## Optimization 问题和改进

### Optimization fails reason

critical point：gradient is close to zero

- local minima
- saddle point

![image-20240127163434897](./assets/image-20240127163434897.png)

#### local point 和 saddle point 的区分

用Taylor展开计算某一个参数$\theta$的loss function

![image-20240127163740027](./assets/image-20240127163740027.png)

>本质上就是在某一个参数点附近二阶taylor展开，看其二阶偏导的正负判断其单调性，以此判断是一个local minima还是saddle point

##### Hessian矩阵

在 critical point

![image-20240127163851568](./assets/image-20240127163851568.png)

![image-20240127164134612](./assets/image-20240127164134612.png)

根据Hessian矩阵计算其特征值，根据特征值判断critical point是一个local minima还是saddle point（前提是一阶梯度为0）

计算实例

![image-20240127164407661](./assets/image-20240127164407661.png)

![image-20240127164450314](./assets/image-20240127164450314.png)

##### saddle point的解决方式

![image-20240127164633051](./assets/image-20240127164633051.png)

![image-20240127164741939](./assets/image-20240127164741939.png)

this method is seldom used in practice

##### 从一个高维的角度

![image-20240127165131236](./assets/image-20240127165131236.png)

>在所有的critical point里，还有一半的特征值为负的，也就是是一个saddle point

### Batch

Optimization with Batch

![image-20240127181728166](./assets/image-20240127181728166.png)

>shuffle：每一个epoch中batch都不一样

#### Small Batch vs Large Batch

![image-20240127181918769](./assets/image-20240127181918769.png)

Larger batch size does not require longer time to compute gradient

- GPU可以做平行计算（parallel computing）

![image-20240127182156942](./assets/image-20240127182156942.png)

![image-20240127182841917](./assets/image-20240127182841917.png)

![image-20240127183042150](./assets/image-20240127183042150.png)

![image-20240127183147485](./assets/image-20240127183147485.png)

![image-20240127183201941](./assets/image-20240127183201941.png)

### Momentum

![image-20240127183422741](./assets/image-20240127183422741.png)

![image-20240127185048042](./assets/image-20240127185048042.png)

![image-20240127185241354](./assets/image-20240127185241354.png)

![image-20240127185253822](./assets/image-20240127185253822.png)

### Adaptive Learning Rate

