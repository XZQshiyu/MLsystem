{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8816255,"sourceType":"datasetVersion","datasetId":5303444}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List\nfrom matplotlib import pyplot as plt\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:24.484231Z","iopub.execute_input":"2024-07-01T07:57:24.484546Z","iopub.status.idle":"2024-07-01T07:57:28.164751Z","shell.execute_reply.started":"2024-07-01T07:57:24.484519Z","shell.execute_reply":"2024-07-01T07:57:28.163814Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:28.168353Z","iopub.execute_input":"2024-07-01T07:57:28.168719Z","iopub.status.idle":"2024-07-01T07:57:41.649971Z","shell.execute_reply.started":"2024-07-01T07:57:28.168695Z","shell.execute_reply":"2024-07-01T07:57:41.648730Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\nDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.7.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tokenization\n\n### 简介\nTokenization 的主要目的是将文本分解成更小的单位(Tokens)，减小模型输入数据的内在结构复杂度(从句子变为单词序列)，从而简化模型训练的难度。同时将字符的序列转化为Token序号的序列，便于模型输入。\n\nTokenization 首先确定语言的词表划分粒度，一般可分为：\n* 字符级：将文本分解为字符。\n* 单词级：将文本分解为单词。\n* 子词级：将单词进一步分解为更小的有意义单元（如前缀、后缀）。\n\n之后使用预定义的规则来识别 tokens, 或使用统计或机器学习技术来识别最优的 token 切分方式。例如，BPE（Byte Pair Encoding）或 SentencePiece。\n\n最后实现一组文本序列和Tokens序列之间相互转化的函数，即可完成Tokenization部分。\n\n### 实验要求\n\n1. 实现字符级切分的简单tokenizer， 由 字符表， 字符到token的 encoder()函数 和 token到字符的 decoder() 函数组成。\n2. 调用 现有的tokenizer实现，比如openai 的tiktoken","metadata":{}},{"cell_type":"code","source":"class Tokenizer:\n    def __init__(\n        self,\n        dataPath:str\n        ):\n        with open(dataPath,\"r\",encoding=\"utf-8\") as f:\n            self.dataset = f.read()\n        self.word2index = {}\n        self.index2word = {}\n        import tiktoken as tk\n        self.enc = tk.get_encoding(\"cl100k_base\")\n        self.token_str = self.enc.decode_single_token_bytes\n        self.generate_vocabulary()\n\n    def generate_vocabulary(\n        self,\n        ):\n        \"\"\"\n        TODO:\n        \"\"\"\n        # 构建两个字典，字符到索引的映射，索引到字符的映射\n        # 0是句子开始符号，1是句子结束符号\n        # 将sos和eos加入到字典中\n        self.word2index[\"<sos>\"] = 0\n        self.word2index[\"<eos>\"] = 1\n        self.index2word[0] = \"<sos>\"\n        self.index2word[1] = \"<eos>\"\n        # unk字符\n        self.word2index[\"<unk>\"] = 2\n        self.index2word[2] = \"<unk>\"\n        # enc_output = self.enc.encode(self.dataset)\n        index = 2\n        # 不区分大小写\n        dataset_lowercase = self.dataset.lower()\n        enc_output = self.enc.encode(dataset_lowercase)\n        for token in enc_output:\n            if self.token_str(token) not in self.word2index:\n                index += 1\n                self.word2index[self.token_str(token)] = index\n                self.index2word[index] = self.token_str(token)\n        self.vocab_size = len(self.word2index)\n        print(\"Vocabulary size: \", self.vocab_size)\n    \n    def encode(\n        self,\n        sentence : str,\n        ) -> torch.Tensor:\n        \"\"\"\n        TODO:\n        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n        input  : \"ABCD\"\n        output : Tensor([0,1,2,3]) \n\n        注意: 为了后续实验方便，输出Tensor的数据类型dtype 为torch.long。\n        \"\"\"\n        # unk\n        sentence = sentence.lower()\n        sentence = self.enc.encode(sentence)\n        for i in range(len(sentence)):\n            if self.token_str(sentence[i]) not in self.word2index:\n                sentence[i] = \"<unk>\"\n            else:\n                sentence[i] = self.token_str(sentence[i])\n        # print(sentence)\n        # return torch.tensor([self.word2index[\"<sos>\"]] + [self.word2index[token] for token in sentence] + [self.word2index[\"<eos>\"]], dtype=torch.long)\n        return torch.tensor([self.word2index[\"<sos>\"]] + [self.word2index[token] for token in sentence], dtype=torch.long)\n\n    def decode(\n        self,\n        tokens : torch.Tensor,\n        ) -> str:\n        \"\"\"\n        TODO:\n        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n        input : Tensor([0,1,2,3]) \n        output : \"ABCD\"\n        \"\"\"\n        ans=\"\"\n        for i in tokens[1:-1]:\n            if(i==1):\n                break\n            if(i==0):\n                continue\n            if(i==2):\n                continue\n            #print(i.item(),self.index2word[i.item()])\n            ans+=self.index2word[i].decode(\"utf-8\")\n        return ans\n\ntokenizer = Tokenizer(dataPath=\"/kaggle/input/input-txt/input.txt\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:41.651997Z","iopub.execute_input":"2024-07-01T07:57:41.652383Z","iopub.status.idle":"2024-07-01T07:57:44.817160Z","shell.execute_reply.started":"2024-07-01T07:57:41.652348Z","shell.execute_reply":"2024-07-01T07:57:44.816223Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Vocabulary size:  10708\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 定义 dataloader 和 dataset\n\n为了高效加载数据，我们需要把输入文件接入 PyTorch 的数据加载器中。在这里我们定义 `ShakespeareDataset` 类用于加载数据集，用 PyTorch 的 `DataLoader` 类来实现数据加载。\n","metadata":{}},{"cell_type":"code","source":"class ShakespeareDataset(Dataset):\n    def __init__(self, filepath, tokenizer, chunk_size):\n        self.tokenizer = tokenizer\n        with open(filepath, 'r', encoding='utf-8') as file:\n            text = file.read()\n        self.encoded = self.tokenizer.encode(text)\n        self.chunk_size = chunk_size\n\n    def __len__(self):\n        return len(self.encoded) - self.chunk_size\n\n    def __getitem__(self, idx):\n        #TODO: 提取一段文本(长度为 chunk_size）作为输入，以及这段文本的每一个字符的下一个字符作为标签\n        # example(not correspond to real text): chunk = tensor([ 0, 20, 49, 58, 59])\n        #         label = tensor([20, 49, 58, 59, 19])\n        # decoded chunk: \"The \"\n        # decoded label: \"he T\"\n        chunk = self.encoded[idx:idx+self.chunk_size]\n        label = self.encoded[idx+1:idx+self.chunk_size+1]\n        return chunk, label\n\ntokenizer = Tokenizer(dataPath=\"/kaggle/input/input-txt/input.txt\")\n\ndef create_dataloader(filepath, tokenizer, chunk_size, batch_size, shuffle=True):\n    dataset = ShakespeareDataset(filepath, tokenizer, chunk_size)\n    \n    train_dataset,val_dataset = torch.utils.data.random_split(dataset,[int(len(dataset)*0.8),len(dataset)-int(len(dataset)*0.8)])\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n    return train_dataloader, val_dataloader\n\n\ntrain_dataloader,val_dataloader = create_dataloader('/kaggle/input/input-txt/input.txt', tokenizer, chunk_size=200, batch_size=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:44.818217Z","iopub.execute_input":"2024-07-01T07:57:44.818489Z","iopub.status.idle":"2024-07-01T07:57:46.350776Z","shell.execute_reply.started":"2024-07-01T07:57:44.818465Z","shell.execute_reply":"2024-07-01T07:57:46.349872Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Vocabulary size:  10708\n","output_type":"stream"}]},{"cell_type":"markdown","source":"注意力的计算公式为：\n$$\nHead = Attention(x)=Softmax(M\\cdot QK^T)V\\\\\nQ=xW_{q},K=xW_{k}, V=xW_{v}\n$$\n这里实现的一些数学技巧可以参见attention.ipynb","metadata":{}},{"cell_type":"code","source":"import math\ndef attention(q, k, v, mask=None, dropout=None):\n    \"Compute ''Scaled Dot Product Attention'\"\n    d_k = q.size(-1)\n    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n    if mask is not None:\n        mask = mask.to(device)\n        scores = scores.masked_fill(mask == 0, -1e9)\n    p_attn = F.softmax(scores, dim = -1)\n    if dropout is not None:\n        p_attn = dropout(p_attn)\n    return torch.matmul(p_attn, v), p_attn\n\nclass HeadAttention(nn.Module):\n    def __init__(self, seq_len:int, embed_size:int, hidden_size:int):\n        super().__init__()\n        # embed_size: dimension for input embedding vector\n        # hidden_size: dimension for hidden vector. eg. x:(..., embed_size) --to_q--> query_vector:(..., hidden_size)\n\n        # a triangular bool matrix for mask\n        self.register_buffer(\"tril\", torch.tril(torch.ones(seq_len, seq_len)))\n        # TODO: init three matrix, to_q, to_k, to_v.\n        self.to_q = nn.Linear(embed_size, hidden_size)\n        self.to_k = nn.Linear(embed_size, hidden_size)\n        self.to_v = nn.Linear(embed_size, hidden_size)\n\n        nn.init.xavier_uniform_(self.to_q.weight)\n        nn.init.xavier_uniform_(self.to_k.weight)\n        nn.init.xavier_uniform_(self.to_v.weight)\n        self.hidden_size = hidden_size\n\n    def forward(self, inputs):\n        # input: (batch_size, seq_len, embed_size)\n        # return (batch_size, seq_len, hidden_size)\n        # TODO: implement the attention mechanism\n        inputs = inputs.to(device)\n        now_len = inputs.size(1)\n        self.tril = torch.ones(now_len, now_len)\n        Q = self.to_q(inputs)\n        K = self.to_k(inputs)\n        V = self.to_v(inputs)\n        ans, _ = attention(Q, K, V, mask=self.tril, dropout=None)\n        return ans\n        # Q: (batch_size, seq_len, hidden_size)\n        # K: (batch_size, seq_len, hidden_size)\n        # V: (batch_size, seq_len, hidden_size)\n        # attention: (batch_size, seq_len, seq_len)\n        # attention = torch.matmul(Q, K.transpose(1,2)) / (K.size(-1) ** 0.5)\n        # attention = attention.masked_fill(self.tril==0, float('-inf'))\n        # attention = F.softmax(attention, dim=-1)\n        # # output: (batch_size, seq_len, hidden_size)\n        # output = torch.matmul(attention, V).to(inputs.device)\n        # return output\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.353490Z","iopub.execute_input":"2024-07-01T07:57:46.353790Z","iopub.status.idle":"2024-07-01T07:57:46.448747Z","shell.execute_reply.started":"2024-07-01T07:57:46.353765Z","shell.execute_reply":"2024-07-01T07:57:46.447767Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Transformer中使用的注意力机制时会使用多个注意力头，期望每个注意力头能够注意到不同的信息。\n所以实际公式需要修改如下\n$$\nMultiHeadAttention(x)=[Head_0, Head_1,...,Head_h]W_o\\\\\nHead_i = Attention(x)=Softmax(M\\cdot Q_iK_i^T)V_i\\\\\nQ_i=xW_{iq},K=xW_{ik}, V=xW_{iv}\n$$\n在搭建网络的过程中，同学们可能会用到nn.ModuleList这个库，每个$Head_i$的计算可以直接使用上面已经实现的单头注意力计算。\n最后对于这些注意力头再使用一个简单的线性层/矩阵$W_o$汇总信息即可","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    # MultiHeadAttention is consist of many HeadAttention output.\n    # concat all this head attention output o_i, then merge them with a projection matrix W_o, as [o_1, o_2, ...] x W_o\n    # The reason for using multi-head attention is that we want each head to be able to extract different features\n    def __init__(self, n_heads:int, head_size:int, seq_len:int, embed_size:int):\n        # n_heads is the number of head attention\n        # head_size is the hidden_size in each HeadAttention\n        super().__init__()\n        head_size = embed_size // n_heads\n        #TODO: implement heads and projection\n        self.heads = nn.ModuleList(\n            [HeadAttention(seq_len, embed_size, head_size) for _ in range(n_heads)]\n        )\n        self.projection = nn.Linear(embed_size,n_heads * head_size)\n        nn.init.xavier_uniform_(self.projection.weight)\n\n\n    def forward(self, inputs):\n        # input: (batch_size, seq_len, embed_size), make sure embed_size=n_heads x head_size\n        # return: (batch_size, seq_len, embed_size)\n        # TODO:\n        output = []\n        inputs = inputs.to(device)\n        for h in self.heads:\n            temp = h(inputs)\n            output.append(temp)\n        # head_outputs = [head(inputs) for head in self.heads]\n        # head_outputs: [(batch_size, seq_len, head_size), ...]\n        # merge all head outputs\n        # output = torch.cat(head_outputs, dim=-1)\n        # output: (batch_size, seq_len, n_heads * head_size)\n        output = torch.cat(output, dim=-1)\n        output = self.projection(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.449837Z","iopub.execute_input":"2024-07-01T07:57:46.450149Z","iopub.status.idle":"2024-07-01T07:57:46.466551Z","shell.execute_reply.started":"2024-07-01T07:57:46.450114Z","shell.execute_reply":"2024-07-01T07:57:46.465720Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 专家网络 Expert\n\nExpert即为标准Transformer中的FeedForward模块。\n\n在经过MultiHeadAttention 模块后，seq_len中的每一个Embedding都对应了前文信息的加权求和。在经过FeedForward模块时，模型对每一个位置的Embedding进行了两次线性变换和一次非线性变换，可以视为对当前语境下的信息进行加工。知识编辑的一些研究表明，FeedForword 模块参数包含了大量的事实性知识。\n\n一个直观的想法是，类比于MultiHeadAttention，我们在每一层训练多个FeedForward模块，对于不同位置的Embedding使用不同的FeedForward模块处理对应的信息。就好像每层有多个Expert,每个Expert都负责处理一类数据的深加工，因此我们称FeedForward为Expert。\n\n实现方面:\n\nFeedForward层由两层简单的线性层组成，对于一个(batch_size, seq_len, embed_size)输入的向量x\n只在最后一个维度上进行计算，以实现词的特征维度上的交互(注意力机制是词之间的交互)。\n其首先用一个线性层将x最后一维扩大至原先4倍，然后继续用一个线性层还原回原先的维度。","metadata":{}},{"cell_type":"code","source":"class Expert(nn.Module):\n    def __init__(self, embed_size:int, dropout=0.1):\n        super().__init__()\n        #TODO: init two linear layer\n        d_model = embed_size\n        d_ff = embed_size * 4\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, inputs):\n        # inputs: (batch_size, seq_len, embed_size)\n        # -> mid: (batch_size, seq_len, 4 x embed_size)\n        # -> outputs: (batch_size, seq_len, embed_size)\n        inputs = inputs.to(device)\n        outputs = self.w_2(self.dropout(F.relu(self.w_1(inputs))))\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.467580Z","iopub.execute_input":"2024-07-01T07:57:46.467896Z","iopub.status.idle":"2024-07-01T07:57:46.481074Z","shell.execute_reply.started":"2024-07-01T07:57:46.467795Z","shell.execute_reply":"2024-07-01T07:57:46.480356Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## 选通网络 TopkRouter\n\n在实现了单个Expert后，我们要设计一个选通网络决策每个Embedding要使用那个Expert计算\n\n\n### 为了说明选通网络的实现方式，我们定义一下记号：\n\ninputs.shape = [batch_size, seq_len, embed_size] = [1, 8, 16] \n\n即输入有batch_size=1个数据点，该数据有seq_len长度的context，即包含seq_len=8个Embedding，每个Embedding长度为embed_dim=16。\n\n记 num_expert = 4, 即该层包含 num_expert 个并列的Expert。\n\n记 active_expert = 2, 即计算每个Embedding仅有 active_expert 个Expert 参与计算。\n\n### 选通网络计算\n对于有seq_len=8的数据，如果每个Expert都参与计算每一个Embedding，那么一共需要计算 seq_len*embed_size = 32 次， 这极大的增加了模型计算量，因此我们往往只激活其中的active_experts个Expert，这要求我们对每一个Embedding计算最合适的active_experts个 Expert。\n\n对于单个Expert 的原版Transformer来说：\n\n$$\noutputs[0,seq] = FeedForward(inputs[0,seq])\n$$\n\n对于多个Expert的网络：\n\n$$\noutputs[0,seq] = \\sum_{i \\in range(num\\_model)} \\alpha_{i} Expert_{i}(inputs[0,seq])\n$$\n\n$$\n\\alpha_{i} = \\left\\{\n\\begin{array}{ll}\n    1 & Expert_{i}  \\text{is selected} \\\\\n    0 & Expert_{i}  \\text{is not selected} \\\\\n\\end{array}\n\\right.\n$$\n将$\\{\\alpha_0,\\alpha_1,\\dots,\\alpha_{num_experts-1}\\}$记为向量$\\alpha$:\n$$\noutputs[0,seq] = \\alpha \\cdot \\{Expert_i(inputs[0,seq])\\}\n$$\n\n一个选通0,2号Expert的$\\alpha$的例子是$[1,0,1,0]$\n\n问题在于如何求得 $\\alpha$, 对于一个Embedding ，我们使用神经网络对每个Expert打分，在根据分数计算$\\alpha$\n\n$$\nscore[0,seq] = MLP(inputs[0,seq])  \\\\\n\\alpha = topK(score[0,seq])\n$$\n\n例如：\n\n$$\nscore[0,seq] = [11.32,1.54,14.83,-1.90] \\\\\n\\alpha = [1,0,1,0]\n$$\n\n从优化的角度来说，$\\alpha$取前k大的分数的下标（即argmax），这个操作是不可导的，这里我们用之前在\"attention.ipynb\"中提到的技巧处理这里的计算。\n\n$$\nmask(score[0,seq]) = [11.32,-inf,14.83,-inf] \\\\\n\\alpha = softmax(mask(score[0,seq])) = [0.028,0,0.971,0] \\\\\nindex = [1,0,1,0]\n$$\n\n我们用这个$\\alpha$和$index$用做选通网络.","metadata":{}},{"cell_type":"code","source":"# First define the top k router module\nclass TopkRouter(nn.Module):\n    def __init__(self, embed_size, num_expert, active_experts):\n        ## TODO:\n        ## embed_size : dimension of embedding \n        ## num_expert : how many Experts per layer\n        ## active_experts: only active_experts out of num_expert are selected to process Embeddings per token.\n        super().__init__()\n        self.embed_size = embed_size\n        self.num_expert = num_expert\n        self.active_experts = active_experts\n        to_experts = nn.Linear(embed_size, num_expert)\n        self.noise = nn.Linear(embed_size, num_expert)\n        nn.init.xavier_uniform_(to_experts.weight)\n        self.to_experts = to_experts\n\n    def forward(self, inputs):\n        ## TODO:\n        ## 完成这部分时，注意使用Softmax()对router_output做标准化。同时注意这部分所用操作的可导性。\n        ## 输入值\n        ## inputs is the output tensor from multihead self attention block, shape (B:batch size, T: seq_len, C: embed_size)\n        ## 返回值\n        ## router_output: normalized weight of Experts, 即教程中的 \\alpha\n        ## indices:   index of selected Experts, 即教程中的 index\n        score = self.to_experts(inputs)\n        rand = torch.rand_like(score)\n        noise = F.softplus(self.noise(inputs))\n        score = score + noise * rand\n        \n        score = torch.sum(score, dim=1)\n        score = torch.sum(score, dim=0)\n\n        score /= (inputs.size(0) * inputs.size(1))\n\n        _, idx = torch.topk(score, self.active_experts, dim=-1)\n        indices = torch.zeros_like(score)\n        indices.scatter_(-1, idx, 1)\n\n        score = score.masked_fill(indices == 0, float(\"-inf\"))\n        router_output = F.softmax(score, dim=-1)\n\n        return router_output, indices","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-07-01T07:57:46.481903Z","iopub.execute_input":"2024-07-01T07:57:46.482142Z","iopub.status.idle":"2024-07-01T07:57:46.495767Z","shell.execute_reply.started":"2024-07-01T07:57:46.482121Z","shell.execute_reply":"2024-07-01T07:57:46.495043Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## 稀疏专家网络 SparseMoE\n\n![moe](./moeSparse.png)\n\n在定义完Expert 和 TopkRouter后，我们可以定义SparseMoE模块。\n\n在前向过程中，对于inputs.shape = [Batch_size,seq_len,embed_size]第二维度seq_len个Embedding,我们先利用TopkRouter计算出选通专家序号indices以及专家权重router_output。\n\n我们将Embedding通过选通的Expert得出active_expert个新的Embedding，然后使用router_output的作为权重对新的Embedding加权求和作为输出。\n","metadata":{"tags":[]}},{"cell_type":"code","source":"class SparseMoE(nn.Module):\n    def __init__(self, embed_size:int, num_expert:int, active_experts:int):\n        ## TODO:\n        super(SparseMoE,self).__init__()\n        self.Router = TopkRouter(embed_size, num_expert, active_experts)\n        self.expert = nn.ModuleList([Expert(embed_size) for _ in range(num_expert)])\n        self.num_expert = num_expert\n    def forward(self, inputs):\n        ## TODO:\n        ## 完成这部分时，注意使用router输出的权重对Expert的输出做加权平均。\n        ## 输入值\n        rounter_output,indices = self.Router(inputs)\n        B,T,C = inputs.size()\n        final_output = torch.zeros(B,T,C).to(device)\n        for j in range(self.num_expert):\n            if(indices[j]==1):\n                final_output+=self.expert[j](inputs)*rounter_output[j]\n        return final_output\n","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.496717Z","iopub.execute_input":"2024-07-01T07:57:46.496988Z","iopub.status.idle":"2024-07-01T07:57:46.509936Z","shell.execute_reply.started":"2024-07-01T07:57:46.496966Z","shell.execute_reply":"2024-07-01T07:57:46.509099Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Transformer由一层层的block堆叠而成，其中每个block的结构从模型的结构图展开中可以看到，由LayerNorm，Masked multi head attention，(SparseMoE)FeedForward组成。\n\n对于一个表示句子的输入向量x，其首先会经过Layer Normalization层.\nLayer Normalization 层对于一个 句子个数x句子长度x单词向量维度 的输入 x, 会在最后两维上进行规范化处理，起到稳定训练的作用。\n\n$$\nLN(x)=\\frac{x-mean(x)}{\\sqrt{var(x)+\\epsilon}}\\cdot\\gamma+\\beta\n$$\n\n其中mean和var都是在最后两个维度上进行的，layernorm的实现同学们可以直接调用nn.LayerNorm\n经过layernorm层后，再经过Mask multi head attention层之后，会在+号处再次和原始的输入进行相加，这样的做法能够提高训练的稳定性。有兴趣的同学可以从梯度角度思考原因，或者搜索残差连接相关资料进行学习。\n之后再同样经过一层layernorm和feedforwad之后，就可以得到block块的输出了。\n即 x' = x+MHA(LN(x)), y = FFN(LN(x'))+x'","metadata":{}},{"cell_type":"code","source":"class Block(nn.Module):\n    # Transformer basic block, consist of MultiHeadAttention, FeedForward and layer normalization\n    def __init__(self, embed_size:int, n_heads:int, seq_len:int, num_expert:int, active_experts:int):\n        super().__init__()\n        # TODO: implement block structure\n        self.MH = MultiHeadAttention(n_heads, embed_size // n_heads, seq_len, embed_size)\n        self.MoE = SparseMoE(embed_size, num_expert, active_experts)\n        self.layer_norm = nn.LayerNorm(embed_size)\n\n\n    def forward(self, inputs):\n        # input: (batch_size, seq_len, embed_size)\n        #TODO: forward with residual connection\n        x = self.MH(self.layer_norm(inputs)) + inputs\n        y = self.MoE(self.layer_norm(x)) + x\n        return y","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.511000Z","iopub.execute_input":"2024-07-01T07:57:46.511247Z","iopub.status.idle":"2024-07-01T07:57:46.523408Z","shell.execute_reply.started":"2024-07-01T07:57:46.511225Z","shell.execute_reply":"2024-07-01T07:57:46.522555Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class SparseMoETransformer(nn.Module):\n    # Transformer decoder, consist of \n    # token embedding layer and position_embedding(position_embedding 可以理解为对位置编码，感兴趣的同学可以查阅原文，这里可以看为vocab_len = seq_len的Embedding)\n    # a stack of Transformer basic block\n    # a layernorm and output linear layer\n    def __init__(self, vocab_size:int, seq_len:int, embed_size:int, n_layers:int, n_heads:int, num_expert:int, active_experts:int):\n        # vocab_size is the number of word in vocabulary dict\n        # seq_len is the sequence length/sentence length\n        # embed_size is the embedding vector dimension\n        super().__init__()\n        # TODO: \n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.position_embedding = nn.Embedding(seq_len, embed_size)\n        self.blocks = nn.ModuleList([Block(embed_size, n_heads, seq_len, num_expert, active_experts) for _ in range(n_layers)])\n        self.output = nn.Linear(embed_size, vocab_size)\n        self.seq_len = seq_len\n\n    def forward(self, inputs, labels=None):\n        # labels: the (ground) true output \n        # TODO: implement the forward function of the transformer\n\n        # inputs:(batch_size, seq_len, )\n        batch_size, seq_len, = inputs.shape\n        # embedding:(batch_size, seq_len, embed_size)\n        embedding = self.embedding(inputs)\n        position_idx = torch.arange(seq_len, device=inputs.device).expand(batch_size, seq_len)\n        position_embedding = self.position_embedding(position_idx)\n\n        # attens:(batch_size, seq_len, embed_size)\n\n        # logits:(batch_size, seq_len, vocab_size)\n        \n        embedding += position_embedding\n\n        for block in self.blocks:\n            embedding = block(embedding)\n\n        logits = self.output(embedding)\n\n        # compute the loss\n        \n        if labels is None:\n            loss = None\n        else:\n            batch_size, seq_len, vocab_size = logits.shape\n            logits = logits.view(batch_size * seq_len, vocab_size)\n            labels = labels.view(batch_size * seq_len)\n            loss = nn.CrossEntropyLoss()(logits, labels)\n        return logits, loss\n    def generate(self, inputs, max_new_tokens):\n        inputs = torch.tensor(tokenizer.encode(inputs)).clone().detach().unsqueeze(0)\n        # inputs = torch.tensor(tokenizer.encode(inputs)).unsqueeze(0)\n        device = next(self.parameters()).device  \n        inputs = inputs.to(device)\n        if inputs.size(1) > self.seq_len:\n            inputs = inputs[:, :self.seq_len]\n        generated = inputs\n        for _ in range(max_new_tokens):\n            if generated.size(1) > self.seq_len:\n                generated_input = generated[:, -self.seq_len:]\n            else:\n                generated_input = generated\n            logits, _ = self.forward(generated_input)\n            last_logits = logits[:, -1, :]  \n            next_token_ids = torch.argmax(last_logits, dim=-1)  \n            next_token_ids = next_token_ids.unsqueeze(-1)  \n            generated = torch.cat([generated, next_token_ids], dim=1)  \n        return generated","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.524590Z","iopub.execute_input":"2024-07-01T07:57:46.524880Z","iopub.status.idle":"2024-07-01T07:57:46.539534Z","shell.execute_reply.started":"2024-07-01T07:57:46.524856Z","shell.execute_reply":"2024-07-01T07:57:46.538808Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 训练循环\n\n如果你已经完成了模型定义等内容，训练的过程实际上在高度封装的 Pytorch 库中非常简单, 因为你并不需要写对应的反向传播。\n\n","metadata":{}},{"cell_type":"markdown","source":"#### Loss \n\nLoss 用来**衡量**模型预测与真实值之间的**差距**。\n\n常见的几个 Loss 函数：\n\n* 交叉熵：$\\text{CrossEntropy Loss} = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)$\n* 均方误差：$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$\n* 绝对误差：$\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y_i}|$\n\n不同的 loss 对应不同的优化目标，如果写错 loss 函数会导致模型不收敛/性能很差。","metadata":{}},{"cell_type":"markdown","source":"#### 训练循环\n\n当我们写好 Optimizer 和 Loss 之后，对应的训练循环就十分简单了。\n\n我们只需要做以下事情：\n\n* 从 dataloader 里面拿到一个 batch 的数据以及标签\n* 将数据送入模型，进行前向传播\n* 拿到模型输出的 logits\n* 将 logits 和 标签进行 loss 计算\n* 用 Optimizer \n    * 清空梯度\n    * 反向传播\n    * 更新参数","metadata":{}},{"cell_type":"code","source":"def train(model, dataloader, epoch, device, lr=1e-3, wd=1e-5, optimizer_func= 'SGD', lr_period=10 , lr_decay=0.1, momentum=0.9):\n    # Optimizer 会根据模型的输出和真实标签计算梯度，然后利用反向传播算法更新模型的参数。\n    # 在本实验中你可以将 Optimizer 视作黑盒，只需要知道如何使用即可。\n    # 找一个合适的 Optimizer。对不同的任务，模型，最适合的优化器是不一样的，你可以先尝试最常用的 Adam，如果有兴趣可以看看其他的优化器。\n    # docs see: https://pytorch.org/docs/stable/optim.html \n    model = model.to(device)\n    if optimizer_func == 'SGD':\n        optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n    elif optimizer_func == 'Adam':\n        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n    else:\n        raise ValueError('Optimizer not supported')\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_period, gamma=lr_decay)\n    model.train()\n    total_loss = 0\n    from tqdm import tqdm\n    for i, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n        # TODO: implement the training process, and compute the training loss and validation loss\n        inputs=inputs.to(device)\n        targets=targets.to(device)\n        _, loss = model.forward(inputs, targets)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    scheduler.step()\n    print(f'Epoch {epoch} Loss: {total_loss / len(dataloader)}')\n\n    return total_loss / len(dataloader)\n\ndef validate(model, dataloader, epoch, device):\n    model = model.to(device)\n    model.eval()\n    # TODO: 实现验证函数。与训练函数类似，但不需要计算梯度。\n    with torch.no_grad():\n        total_loss = 0\n        for i, (inputs, targets) in enumerate(dataloader):\n            inputs=inputs.to(device)\n            targets=targets.to(device)\n            _, loss = model.forward(inputs, targets)\n            total_loss += loss.item()\n        print(f'Epoch {epoch} Validation Loss: {total_loss / len(dataloader)}')\n    \n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.540581Z","iopub.execute_input":"2024-07-01T07:57:46.540890Z","iopub.status.idle":"2024-07-01T07:57:46.554420Z","shell.execute_reply.started":"2024-07-01T07:57:46.540866Z","shell.execute_reply":"2024-07-01T07:57:46.553689Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"EBD_SIZE, TRANS_N, EPOCH_NUM = 64, 6, 4\nlearning_rate = 1e-3\nweight_decay = 1e-5\nlr_period = 5\nlr_decay = 0.5\nmomentum = 0.9\noptimizer_func = 'Adam'\n\ntrain_dataloader, val_dataloader = create_dataloader(\n    '/kaggle/input/input-txt/input.txt', \n    tokenizer, \n    chunk_size=50, \n    batch_size=512\n)\n\nmodel = SparseMoETransformer(\n    vocab_size=len(tokenizer.word2index),\n    seq_len=50,\n    embed_size=EBD_SIZE, \n    n_layers=TRANS_N, \n    n_heads=8, \n    num_expert=8, \n    active_experts=2\n).to(device)\nmodel = model.to(device)\nimport time\n# 训练模型\ndef run(model, train_dataloader, valid_dataloader, device, epochs=10):\n    train_losses = []\n    valid_losses = []\n    for epoch in range(epochs):\n        start_time = time.time()\n        train_loss = train(model, train_dataloader, epoch, device, lr=learning_rate, wd=weight_decay, optimizer_func=optimizer_func, lr_period=lr_period, lr_decay=lr_decay, momentum=momentum)\n        valid_loss = validate(model, valid_dataloader, epoch, device)\n        print(f'Epoch {epoch} Train Loss: {train_loss}, Valid Loss: {valid_loss}')\n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        end_time = time.time()\n        print(f'Epoch {epoch} Time: {end_time - start_time}')\n    return train_losses, valid_losses\n\n#TODO: 用 matplotlib plot 训练过程中的 loss 变化\n\ndef plot_loss(train_loss, valid_loss):\n    plt.plot(train_loss, label='Train Loss')\n    plt.plot(valid_loss, label='Valid Loss')\n    plt.legend()\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n\n    # 使用对数刻度显示损失变化\n    plt.yscale('log')\n\n    plt.show()\ntrain_losses, valid_losses = run(\n    model, train_dataloader, val_dataloader, device, epochs=EPOCH_NUM\n)\n\nplot_loss(train_losses, valid_losses)\n\n# 保存模型\ntorch.save(model.state_dict(), '/kaggle/working/model.pth')\n\nmodel.load_state_dict(torch.load('/kaggle/working/model.pth'))\n\nprint(tokenizer.decode(model.generate(\"I could pick my lance\",max_new_tokens=100)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T07:57:46.555553Z","iopub.execute_input":"2024-07-01T07:57:46.556034Z","iopub.status.idle":"2024-07-01T08:03:40.961348Z","shell.execute_reply.started":"2024-07-01T07:57:46.556004Z","shell.execute_reply":"2024-07-01T08:03:40.960369Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 466/466 [01:20<00:00,  5.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0 Loss: 5.222790548218167\nEpoch 0 Validation Loss: 1.9776814034861376\nEpoch 0 Train Loss: 5.222790548218167, Valid Loss: 1.9776814034861376\nEpoch 0 Time: 89.37542939186096\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 466/466 [01:19<00:00,  5.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 0.5182501900733285\nEpoch 1 Validation Loss: 0.12849816189617172\nEpoch 1 Train Loss: 0.5182501900733285, Valid Loss: 0.12849816189617172\nEpoch 1 Time: 87.309645652771\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 466/466 [01:19<00:00,  5.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.12095898644031373\nEpoch 2 Validation Loss: 0.1051936745006814\nEpoch 2 Train Loss: 0.12095898644031373, Valid Loss: 0.1051936745006814\nEpoch 2 Time: 86.3924560546875\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 466/466 [01:19<00:00,  5.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.10815881555620181\nEpoch 3 Validation Loss: 0.10225966177944444\nEpoch 3 Train Loss: 0.10815881555620181, Valid Loss: 0.10225966177944444\nEpoch 3 Time: 86.48726224899292\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoiUlEQVR4nO3dd3hT5cPG8W/SvcuGsjcUSlkFARkqyFAEcSIiIIrKUERUXCwH/sSBQgE3vgqIIEvZoIiyR9lDkL13J13Jef+IVCultKXtSZv7c125PDk5Se6ksb0558l5LIZhGIiIiIi4IKvZAURERETMoiIkIiIiLktFSERERFyWipCIiIi4LBUhERERcVkqQiIiIuKyVIRERETEZakIiYiIiMtSERIRERGXpSIk4qR69+5NpUqVcnTfkSNHYrFYcjeQkzl8+DAWi4UpU6bk+3NbLBZGjhyZdn3KlClYLBYOHz58w/tWqlSJ3r1752qem/msiLg6FSGRbLJYLFm6rFy50uyoLu/ZZ5/FYrFw4MCB627z2muvYbFY2L59ez4my76TJ08ycuRItm7danaUNFfL6Pvvv292FJEcczc7gEhB8+2336a7/n//938sW7bsmvW1a9e+qef5/PPPsdvtObrv66+/zrBhw27q+QuDHj16MH78eKZNm8bw4cMz3Gb69OmEhYVRr169HD9Pz549efjhh/Hy8srxY9zIyZMnGTVqFJUqVaJ+/frpbruZz4qIq1MREsmmRx99NN31devWsWzZsmvW/1dCQgK+vr5Zfh4PD48c5QNwd3fH3V3/ezdt2pRq1aoxffr0DIvQ2rVrOXToEO++++5NPY+bmxtubm439Rg342Y+KyKuTofGRPJAmzZtqFu3Lps3b6ZVq1b4+vry6quvAjBv3jzuuusuQkJC8PLyomrVqrz55pvYbLZ0j/HfcR//Pgzx2WefUbVqVby8vIiIiGDjxo3p7pvRGCGLxcLAgQOZO3cudevWxcvLizp16rB48eJr8q9cuZLGjRvj7e1N1apV+fTTT7M87uj333/ngQceoEKFCnh5eVG+fHmef/55rly5cs3r8/f358SJE3Tt2hV/f39KlCjB0KFDr3kvLl++TO/evQkKCiI4OJhevXpx+fLlG2YBx16hvXv3smXLlmtumzZtGhaLhe7du5OcnMzw4cNp1KgRQUFB+Pn50bJlS3799dcbPkdGY4QMw+Ctt96iXLly+Pr6ctttt7Fr165r7nvx4kWGDh1KWFgY/v7+BAYG0rFjR7Zt25a2zcqVK4mIiACgT58+aYdfr46PymiMUHx8PC+88ALly5fHy8uLmjVr8v7772MYRrrtsvO5yKmzZ8/St29fSpUqhbe3N+Hh4XzzzTfXbPf999/TqFEjAgICCAwMJCwsjI8//jjt9pSUFEaNGkX16tXx9vamWLFi3HrrrSxbtizXsorr0T8ZRfLIhQsX6NixIw8//DCPPvoopUqVAhx/NP39/RkyZAj+/v788ssvDB8+nJiYGMaOHXvDx502bRqxsbE89dRTWCwW3nvvPbp168bBgwdvuGfgjz/+YPbs2fTv35+AgAA++eQT7rvvPo4ePUqxYsUAiIqKokOHDpQpU4ZRo0Zhs9kYPXo0JUqUyNLrnjlzJgkJCTzzzDMUK1aMDRs2MH78eI4fP87MmTPTbWuz2Wjfvj1Nmzbl/fffZ/ny5XzwwQdUrVqVZ555BnAUii5duvDHH3/w9NNPU7t2bebMmUOvXr2ylKdHjx6MGjWKadOm0bBhw3TP/cMPP9CyZUsqVKjA+fPn+eKLL+jevTtPPvkksbGxfPnll7Rv354NGzZcczjqRoYPH85bb71Fp06d6NSpE1u2bOHOO+8kOTk53XYHDx5k7ty5PPDAA1SuXJkzZ87w6aef0rp1a3bv3k1ISAi1a9dm9OjRDB8+nH79+tGyZUsAmjdvnuFzG4bBPffcw6+//krfvn2pX78+S5Ys4cUXX+TEiRN89NFH6bbPyucip65cuUKbNm04cOAAAwcOpHLlysycOZPevXtz+fJlnnvuOQCWLVtG9+7dueOOO/jf//4HwJ49e1i9enXaNiNHjmTMmDE88cQTNGnShJiYGDZt2sSWLVto167dTeUUF2aIyE0ZMGCA8d//lVq3bm0AxuTJk6/ZPiEh4Zp1Tz31lOHr62skJiamrevVq5dRsWLFtOuHDh0yAKNYsWLGxYsX09bPmzfPAIyffvopbd2IESOuyQQYnp6exoEDB9LWbdu2zQCM8ePHp63r3Lmz4evra5w4cSJt3f79+w13d/drHjMjGb2+MWPGGBaLxThy5Ei61wcYo0ePTrdtgwYNjEaNGqVdnzt3rgEY7733Xtq61NRUo2XLlgZgfP311zfMFBERYZQrV86w2Wxp6xYvXmwAxqeffpr2mElJSenud+nSJaNUqVLG448/nm49YIwYMSLt+tdff20AxqFDhwzDMIyzZ88anp6exl133WXY7fa07V599VUDMHr16pW2LjExMV0uw3D8rL28vNK9Nxs3brzu6/3vZ+Xqe/bWW2+l2+7+++83LBZLus9AVj8XGbn6mRw7dux1txk3bpwBGN99913auuTkZKNZs2aGv7+/ERMTYxiGYTz33HNGYGCgkZqaet3HCg8PN+66665MM4lklw6NieQRLy8v+vTpc816Hx+ftOXY2FjOnz9Py5YtSUhIYO/evTd83IceeogiRYqkXb+6d+DgwYM3vG/btm2pWrVq2vV69eoRGBiYdl+bzcby5cvp2rUrISEhadtVq1aNjh073vDxIf3ri4+P5/z58zRv3hzDMIiKirpm+6effjrd9ZYtW6Z7LQsXLsTd3T1tDxE4xuQMGjQoS3nAMa7r+PHjrFq1Km3dtGnT8PT05IEHHkh7TE9PTwDsdjsXL14kNTWVxo0bZ3hYLTPLly8nOTmZQYMGpTucOHjw4Gu29fLywmp1/Cq22WxcuHABf39/atasme3nvWrhwoW4ubnx7LPPplv/wgsvYBgGixYtSrf+Rp+Lm7Fw4UJKly5N9+7d09Z5eHjw7LPPEhcXx2+//QZAcHAw8fHxmR7mCg4OZteuXezfv/+mc4lcpSIkkkfKli2b9of133bt2sW9995LUFAQgYGBlChRIm2gdXR09A0ft0KFCumuXy1Fly5dyvZ9r97/6n3Pnj3LlStXqFat2jXbZbQuI0ePHqV3794ULVo0bdxP69atgWtfn7e39zWH3P6dB+DIkSOUKVMGf3//dNvVrFkzS3kAHn74Ydzc3Jg2bRoAiYmJzJkzh44dO6Yrld988w316tVLG39SokQJFixYkKWfy78dOXIEgOrVq6dbX6JEiXTPB47S9dFHH1G9enW8vLwoXrw4JUqUYPv27dl+3n8/f0hICAEBAenWX/0m49V8V93oc3Ezjhw5QvXq1dPK3vWy9O/fnxo1atCxY0fKlSvH448/fs04pdGjR3P58mVq1KhBWFgYL774otOf9kCcn4qQSB75956Rqy5fvkzr1q3Ztm0bo0eP5qeffmLZsmVpYyKy8hXo6307yfjPINjcvm9W2Gw22rVrx4IFC3j55ZeZO3cuy5YtSxvU+9/Xl1/ftCpZsiTt2rXjxx9/JCUlhZ9++onY2Fh69OiRts13331H7969qVq1Kl9++SWLFy9m2bJl3H777Xn61fR33nmHIUOG0KpVK7777juWLFnCsmXLqFOnTr59JT6vPxdZUbJkSbZu3cr8+fPTxjd17Ngx3ViwVq1a8ddff/HVV19Rt25dvvjiCxo2bMgXX3yRbzml8NFgaZF8tHLlSi5cuMDs2bNp1apV2vpDhw6ZmOofJUuWxNvbO8MTEGZ2UsKrduzYwZ9//sk333zDY489lrb+Zr7VU7FiRVasWEFcXFy6vUL79u3L1uP06NGDxYsXs2jRIqZNm0ZgYCCdO3dOu33WrFlUqVKF2bNnpzucNWLEiBxlBti/fz9VqlRJW3/u3Llr9rLMmjWL2267jS+//DLd+suXL1O8ePG069k5U3jFihVZvnw5sbGx6fYKXT30ejVffqhYsSLbt2/Hbren2yuUURZPT086d+5M586dsdvt9O/fn08//ZQ33ngjbY9k0aJF6dOnD3369CEuLo5WrVoxcuRInnjiiXx7TVK4aI+QSD66+i/vf/9LOzk5mYkTJ5oVKR03Nzfatm3L3LlzOXnyZNr6AwcOXDOu5Hr3h/SvzzCMdF+Bzq5OnTqRmprKpEmT0tbZbDbGjx+frcfp2rUrvr6+TJw4kUWLFtGtWze8vb0zzb5+/XrWrl2b7cxt27bFw8OD8ePHp3u8cePGXbOtm5vbNXteZs6cyYkTJ9Kt8/PzA8jSaQM6deqEzWZjwoQJ6dZ/9NFHWCyWLI/3yg2dOnXi9OnTzJgxI21damoq48ePx9/fP+2w6YULF9Ldz2q1pp3kMikpKcNt/P39qVatWtrtIjmhPUIi+ah58+YUKVKEXr16pU3/8O233+brIYgbGTlyJEuXLqVFixY888wzaX9Q69ate8PpHWrVqkXVqlUZOnQoJ06cIDAwkB9//PGmxpp07tyZFi1aMGzYMA4fPkxoaCizZ8/O9vgZf39/unbtmjZO6N+HxQDuvvtuZs+ezb333stdd93FoUOHmDx5MqGhocTFxWXrua6eD2nMmDHcfffddOrUiaioKBYtWpRuL8/V5x09ejR9+vShefPm7Nixg6lTp6bbkwRQtWpVgoODmTx5MgEBAfj5+dG0aVMqV658zfN37tyZ2267jddee43Dhw8THh7O0qVLmTdvHoMHD043MDo3rFixgsTExGvWd+3alX79+vHpp5/Su3dvNm/eTKVKlZg1axarV69m3LhxaXusnnjiCS5evMjtt99OuXLlOHLkCOPHj6d+/fpp44lCQ0Np06YNjRo1omjRomzatIlZs2YxcODAXH094mLM+bKaSOFxva/P16lTJ8PtV69ebdxyyy2Gj4+PERISYrz00kvGkiVLDMD49ddf07a73tfnM/qqMv/5Ovf1vj4/YMCAa+5bsWLFdF/nNgzDWLFihdGgQQPD09PTqFq1qvHFF18YL7zwguHt7X2dd+Efu3fvNtq2bWv4+/sbxYsXN5588sm0r2P/+6vfvXr1Mvz8/K65f0bZL1y4YPTs2dMIDAw0goKCjJ49expRUVFZ/vr8VQsWLDAAo0yZMtd8Zd1utxvvvPOOUbFiRcPLy8to0KCB8fPPP1/zczCMG3993jAMw2azGaNGjTLKlClj+Pj4GG3atDF27tx5zfudmJhovPDCC2nbtWjRwli7dq3RunVro3Xr1umed968eUZoaGjaqQyuvvaMMsbGxhrPP/+8ERISYnh4eBjVq1c3xo4dm+7r/FdfS1Y/F/919TN5vcu3335rGIZhnDlzxujTp49RvHhxw9PT0wgLC7vm5zZr1izjzjvvNEqWLGl4enoaFSpUMJ566inj1KlTadu89dZbRpMmTYzg4GDDx8fHqFWrlvH2228bycnJmeYUyYzFMJzon6Ii4rS6du2qry6LSKGjMUIico3/Toexf/9+Fi5cSJs2bcwJJCKSR7RHSESuUaZMGXr37k2VKlU4cuQIkyZNIikpiaioqGvOjSMiUpBpsLSIXKNDhw5Mnz6d06dP4+XlRbNmzXjnnXdUgkSk0NEeIREREXFZGiMkIiIiLktFSERERFyWxghlwm63c/LkSQICArJ1ensRERExj2EYxMbGEhIScs2Ev/+lIpSJkydPUr58ebNjiIiISA4cO3aMcuXKZbqNilAmrp76/dixYwQGBpqcRkRERLIiJiaG8uXLp5t0+HpUhDJx9XBYYGCgipCIiEgBk5VhLRosLSIiIi5LRUhERERclopQBiIjIwkNDSUiIsLsKCIiIpKHdGbpTMTExBAUFER0dLTGCImIFAI2m42UlBSzY0gu8PDwwM3NLcPbsvP3W4OlRUSk0DMMg9OnT3P58mWzo0guCg4OpnTp0jd1rj8VIRERKfSulqCSJUvi6+urk+QWcIZhkJCQwNmzZwEoU6ZMjh9LRUhERAo1m82WVoKKFStmdhzJJT4+PgCcPXuWkiVLXvcw2Y1osLSIiBRqV8cE+fr6mpxEctvVn+nNjPtSERIREZegw2GFT278TFWERERExGWpCImIiLiQSpUqMW7cOLNjOA0VIRERESdksVgyvYwcOTJHj7tx40b69et3U9natGnD4MGDb+oxnIW+NWaSszGJnIpOJLx8sNlRRETECZ06dSptecaMGQwfPpx9+/alrfP3909bNgwDm82Gu/uN/6yXKFEid4MWcNojZIK9p2Po9Mkf9P1mE2djE82OIyIiTqh06dJpl6CgICwWS9r1vXv3EhAQwKJFi2jUqBFeXl788ccf/PXXX3Tp0oVSpUrh7+9PREQEy5cvT/e4/z00ZrFY+OKLL7j33nvx9fWlevXqzJ8//6ay//jjj9SpUwcvLy8qVarEBx98kO72iRMnUr16dby9vSlVqhT3339/2m2zZs0iLCwMHx8fihUrRtu2bYmPj7+pPJlRETJBhaK+FPXz4HxcEs9OjyLVZjc7koiISzEMg4TkVFMuuTmz1bBhw3j33XfZs2cP9erVIy4ujk6dOrFixQqioqLo0KEDnTt35ujRo5k+zqhRo3jwwQfZvn07nTp1okePHly8eDFHmTZv3syDDz7Iww8/zI4dOxg5ciRvvPEGU6ZMAWDTpk08++yzjB49mn379rF48WJatWoFOPaCde/enccff5w9e/awcuVKunXrlqvv2X/p0JgJfD3dmdijEV0m/MG6gxcZt3w/Q9vXNDuWiIjLuJJiI3T4ElOee/fo9vh65s6f39GjR9OuXbu060WLFiU8PDzt+ptvvsmcOXOYP38+AwcOvO7j9O7dm+7duwPwzjvv8Mknn7BhwwY6dOiQ7Uwffvghd9xxB2+88QYANWrUYPfu3YwdO5bevXtz9OhR/Pz8uPvuuwkICKBixYo0aNAAcBSh1NRUunXrRsWKFQEICwvLdobs0B4hk1Qr6c+Y++oBMOHXA/y676zJiUREpKBp3LhxuutxcXEMHTqU2rVrExwcjL+/P3v27LnhHqF69eqlLfv5+REYGJg2fUV27dmzhxYtWqRb16JFC/bv34/NZqNdu3ZUrFiRKlWq0LNnT6ZOnUpCQgIA4eHh3HHHHYSFhfHAAw/w+eefc+nSpRzlyCrtETLRPeEhbDx0kW/XHeH5GVtZ8GxLygb7mB1LRKTQ8/FwY/fo9qY9d27x8/NLd33o0KEsW7aM999/n2rVquHj48P9999PcnJypo/j4eGR7rrFYsFuz5thGwEBAWzZsoWVK1eydOlShg8fzsiRI9m4cSPBwcEsW7aMNWvWsHTpUsaPH89rr73G+vXrqVy5cp7k0R6hDERGRhIaGkpERESeP9frd9emXrkgLiekMGDqFpJTNV5IRCSvWSwWfD3dTbnk5RmuV69eTe/evbn33nsJCwujdOnSHD58OM+eLyO1a9dm9erV1+SqUaNG2nxg7u7utG3blvfee4/t27dz+PBhfvnlF8Dxs2nRogWjRo0iKioKT09P5syZk2d5tUcoAwMGDGDAgAHExMQQFBSUp8/l5e5G5CMNueuT39l67DJjFu1hROc6efqcIiJSOFWvXp3Zs2fTuXNnLBYLb7zxRp7t2Tl37hxbt25Nt65MmTK88MILRERE8Oabb/LQQw+xdu1aJkyYwMSJEwH4+eefOXjwIK1ataJIkSIsXLgQu91OzZo1Wb9+PStWrODOO++kZMmSrF+/nnPnzlG7du08eQ2gPUJOoXxRXz58sD4AX68+zMIdpzK/g4iISAY+/PBDihQpQvPmzencuTPt27enYcOGefJc06ZNo0GDBukun3/+OQ0bNuSHH37g+++/p27dugwfPpzRo0fTu3dvAIKDg5k9eza33347tWvXZvLkyUyfPp06deoQGBjIqlWr6NSpEzVq1OD111/ngw8+oGPHjnnyGgAsRl5+J62Au7pHKDo6msDAwDx/vjGL9vDpbwfx93Lnp0G3Urm4343vJCIimUpMTOTQoUNUrlwZb29vs+NILrrezzY7f7+1R8iJvHhnTZpUKkpcUirPfLeZxBSb2ZFEREQKNRUhJ+LuZuWT7g0o5ufJ3tOxjJi3y+xIIiIihZqKkJMpHeTNxw83wGKBGZuOMWvzcbMjiYiIFFoqQk7o1urFGXxHDQBen7uDvadjTE4kIiJSOKkIOalBt1ejZfXiJKbY6T91C3FJqWZHEhERKXRUhJyU1Wph3EP1KR3ozcFz8Qz7cXueTjonIiLiilSEnFgxfy8iezTA3Wrh5+2n+HbdEbMjiYiIFCoqQk6uUcWiDOtYC4A3f97NtmOXzQ0kIiJSiKgIFQB9b61M+zqlSLEZ9J+6hcsJmU+eJyIiIlmjIlQAWCwW3rs/nApFfTlx+Qov/LANu13jhURE5MbatGnD4MGD065XqlSJcePGZXofi8XC3Llz8zSXs1ARKiCCfDyY2KMhnu5WVuw9y6erDpodSURE8lDnzp3p0KFDhrf9/vvvWCwWtm/fnu3H3bhxI/369bupbL1796Zr16439RjOQkWoAKlbNoiRf89M//7Sfaw/eMHkRCIiklf69u3LsmXLOH782hPrfv311zRu3Jh69epl+3FLlCiBr69vbkQsFFSECpjuTcpzb4Oy2OwGg6ZHcS42yexIIiKSB+6++25KlCjBlClT0q2Pi4tj5syZ9O3blwsXLtC9e3fKli2Lr68vYWFhTJ8+PdPH/e+hsf3799OqVSu8vb0JDQ1l2bJlN539t99+o0mTJnh5eVGmTBmGDRtGauo/58ObNWsWYWFh+Pj4UKxYMdq2bUt8fDwAK1eupEmTJvj5+REcHEyLFi04ciTvvjWtIlTAWCwW3r63LtVL+nM2Nonnvo/CpvFCIiLZYxiQHG/OJYvnhHN3d+exxx5jypQp6c4jN3PmTGw2G927dycxMZFGjRqxYMECdu7cSb9+/ejZsycbNmzI0nPY7Xa6deuGp6cn69evZ/Lkybz88ss5ekuvOnHiBJ06dSIiIoJt27YxadIkvvzyS9566y0ATp06Rffu3Xn88cfZs2cPK1eupFu3bhiGQWpqKl27dqV169Zs376dtWvX0q9fPywWy01lyox7nj2y5BlfT3cmPdqQeyasZs1fFxi3/E9euLOm2bFERAqOlAR4J8Sc5371JHj6ZWnTxx9/nLFjx/Lbb7/Rpk0bwHFY7L777iMoKIigoCCGDh2atv2gQYNYsmQJP/zwA02aNLnh4y9fvpy9e/eyZMkSQkIc78c777xDx44ds/+6/jZx4kTKly/PhAkTsFgs1KpVi5MnT/Lyyy8zfPhwTp06RWpqKt26daNixYoAhIWFAXDx4kWio6O5++67qVq1KgC1a9fOcZas0B6hDERGRhIaGkpERITZUa6rWskAxnRzfHDG/3KAlfvOmpxIRERyW61atWjevDlfffUVAAcOHOD333+nb9++ANhsNt58803CwsIoWrQo/v7+LFmyhKNHj2bp8ffs2UP58uXTShBAs2bNbirznj17aNasWbq9OC1atCAuLo7jx48THh7OHXfcQVhYGA888ACff/45ly5dAqBo0aL07t2b9u3b07lzZz7++GNOnTp1U3luRHuEMjBgwAAGDBhATEwMQUFBZse5ri71y7Lh0EWmrj/K8zO2suDZloQE+5gdS0TE+Xn4OvbMmPXc2dC3b18GDRpEZGQkX3/9NVWrVqV169YAjB07lo8//phx48YRFhaGn58fgwcPJjnZec835+bmxrJly1izZg1Lly5l/PjxvPbaa6xfv57KlSvz9ddf8+yzz7J48WJmzJjB66+/zrJly7jlllvyJI/2CBVwb9wdSt2ygVxKSGHAtC0kp9rNjiQi4vwsFsfhKTMu2Rzv8uCDD2K1Wpk2bRr/93//x+OPP562t2X16tV06dKFRx99lPDwcKpUqcKff/6Z5ceuXbs2x44dS7fXZd26ddnKl9Fjrl27Nt24ptWrVxMQEEC5cuUAx3jXFi1aMGrUKKKiovD09GTOnDlp2zdo0IBXXnmFNWvWULduXaZNm3ZTmTKjIlTAeXu4MfGRRgR4uxN19DLvLtprdiQREclF/v7+PPTQQ7zyyiucOnWK3r17p91WvXr1tL0re/bs4amnnuLMmTNZfuy2bdtSo0YNevXqxbZt2/j999957bXXsnTf6Ohotm7dmu5y7Ngx+vfvz7Fjxxg0aBB79+5l3rx5jBgxgiFDhmC1Wlm/fj3vvPMOmzZt4ujRo8yePZtz585Ru3ZtDh06xCuvvMLatWs5cuQIS5cuZf/+/Xk6TkhFqBCoUMyXDx4IB+Cr1YdYtCNvj6eKiEj+6tu3L5cuXaJ9+/bpxvO8/vrrNGzYkPbt29OmTRtKly6drRMdWq1W5syZw5UrV2jSpAlPPPEEb7/9dpbuu3LlSho0aJDuMmrUKMqWLcvChQvZsGED4eHhPP300/Tt25fXX38dgMDAQFatWkWnTp2oUaMGr7/+Oh988AEdO3bE19eXvXv3ct9991GjRg369evHgAEDeOqpp7L1fmWHxTCy+D0+F3R1jFB0dDSBgYFmx7mhdxbu4bNVBwnwcuenQbdSqXjWvpUgIlKYJSYmcujQISpXroy3t7fZcSQXXe9nm52/39ojVIi82L4mEZWKEJuUSv+pW0hMsZkdSURExKmpCBUiHm5WxndvSDE/T3afimHUT7vMjiQiIuLUVIQKmdJB3nz8cAMsFpi+4Rizt1w7R42IiIg4qAgVQrdWL85zd1QH4LU5O/nzTKzJiURERJyTilAhNej26rSsXpwrKTae+W4z8UmpN76TiEghpu8GFT658TNVESqk3KwWxj1Un9KB3vx1Lp5XZu/QLwERcUkeHh4AJCQkmJxEctvVn+nVn3FOaIqNQqyYvxfjH2nAw5+tY/62k0RULkrPWyqaHUtEJF+5ubkRHBzM2bOOORl9fX3zdDZzyXuGYZCQkMDZs2cJDg7Gzc0tx4+lIlTIRVQqyssdavLOwr28+dNuwssFUa9csNmxRETyVenSpQHSypAUDsHBwWk/25zSCRUzUdBOqHg9hmHQ79vNLNt9hnJFfFgwqCVBvjnfjSgiUlDZbDZSUlLMjiG5wMPD47p7grLz91tFKBOFpQgBRF9J4e7xv3Ps4hXa1i7F54810q5hEREplHRmablGkI8HEx9phKebleV7zvDZqoNmRxIRETGdipALCSsXxPDOoQC8t2QfGw5dNDmRiIiIuVSEXEyPphXoUj8Em91g0PQtnI9LMjuSiIiIaVSEXIzFYuGde8OoVtKfMzFJPPd9FDa7homJiIhrUhFyQX5e7kzq0RAfDzdWH7jAxyv2mx1JRETEFCpCLqp6qQDe6VYXgPG/7GfVn+dMTiQiIpL/VIRc2L0NytG9SQUMAwbP2Mqp6CtmRxIREclXKkIubkTnUOqEBHIxPpmB06JIsdnNjiQiIpJvVIQyEBkZSWhoKBEREWZHyXPeHm5M7NGQAG93Nh+5xP8W7TU7koiISL7RmaUzUZjOLH0ji3ee5unvNgMw+dFGdKh7c3O3iIiImEVnlpZs61C3NE/cWhmAF2du48iFeJMTiYiI5D0VIUnzcsdaNKpYhNikVPpP3UJiis3sSCIiInlKRUjSeLhZmfBIA4r6ebLrZAyjftptdiQREZE8pSIk6ZQJ8mHcQ/WxWGD6hqPMiTpudiQREZE8oyIk12hVowSDbq8OwKuzd/LnmViTE4mIiOQNFSHJ0HN3VOfWasW5kmKj/9QtxCelmh1JREQk16kISYbcrBbGPVyfUoFeHDgbx6tzdqAzLYiISGGjIiTXVdzfiwmPNMTNamHe1pNM23DU7EgiIiK5SkVIMhVRqSgvta8JwKj5u9l5ItrkRCIiIrlHRUhuqF+rKrStXYpkm51npm4m+kqK2ZFERERyhYqQ3JDFYuGDB8IpV8SHYxev8OLMbRovJCIihYKKkGRJkK8HE3s0xNPNytLdZ/ji90NmRxIREblpKkKSZfXKBfPG3bUBeHfxXjYdvmhyIhERkZujIiTZ8ugtFekcHoLNbjBwWhQX4pLMjiQiIpJjKkKSLRaLhTHdwqhSwo/TMYkMnrEVm13jhUREpGBSEZJs8/dyZ1KPRnh7WPl9/3nG/7Lf7EgiIiI5oiIkOVKzdABvdw0D4OMV+/l9/zmTE4mIiGSfipDk2H2NyvFwRHkMAwZ/v5XT0YlmRxIREckWFSG5KSPvqUNomUAuxCczcNoWUmx2syOJiIhkmYqQ3BRvDzcm9mhIgJc7m45cYuySfWZHEhERyTIVIblplYr7MfaBegB8tuogS3edNjmRiIhI1qgISa7oULcMj7eoDMALM7dx9EKCyYlERERuTEVIcs2wjrVoUCGY2MRU+k/bTGKKzexIIiIimVIRklzj6W4l8pGGFPH1YOeJGN78ebfZkURERDKlIiS5KiTYh48eqo/FAlPXH2Xe1hNmRxIREbkuFSHJdW1qlmTgbdUAeGX2Dg6cjTU5kYiISMZUhCRPDG5bg+ZVi5GQbOOZ77aQkJxqdiQREZFrqAhJnnCzWvj44QaUDPBi/9k4XpuzE8PQ5KwiIuJcVIQkz5QI8GJ89wa4WS3MiTrB9A3HzI4kIiKSjoqQ5KmmVYox9M6aAIz8aRc7T0SbnEhEROQfKkKS555qVYU7apUkOdVO/6lbiL6SYnYkERERQEVI8oHVauGDB8MpG+zD0YsJvDhzm8YLiYiIU1ARMkvMKTj0u9kp8k2wrycTezTE083K0t1n+PKPQ2ZHEhERURHKSGRkJKGhoUREROTNE5zaBpFN4YfHIP583jyHEwovH8zrd9cG4N1Fe9l85KLJiURExNWpCGVgwIAB7N69m40bN+bNE5QMheDycOUiLHo5b57DSfW8pSKdw0NItRsMmBrFhbgksyOJiIgLUxEyg5sH3PMJWKywcxb8ucTsRPnGYrEwplsYVUr4cTomked/2IbdrvFCIiJiDhUhs5RtBLf0dyz/PASSXGcaCn8vdyb1aIS3h5VVf55jwq8HzI4kIiIuSkXITLe9CsEVIeY4LB9ldpp8VbN0AG91DQPgo+V/svqA64yVEhER56EiZCZPP+j8sWN54xdwdJ25efLZ/Y3K8WDjchgGPPd9FGdiEs2OJCIiLkZFyGxVb4P6jwIGzB8Eqa41eHh0l7rUKh3A+bhkBk2LItVmNzuSiIi4EBUhZ3Dnm+BXEs7/CaveNztNvvL2cGPSo43w93Jnw+GLjF26z+xIIiLiQlSEnIFvUej0nmP5jw/hzC5z8+SzysX9eO/+egB8+ttBlu0+Y3IiERFxFSpCziK0K9S8C+ypjkNkdpvZifJVp7Ay9G5eCYAXftjKsYsJ5gYSERGXoCLkLCwWuOt98AqEE5th/WSzE+W7VzvVpn75YGISUxkwbQtJqa5VBkVEJP+pCDmTwBBoN9qx/MtbcOmwqXHym6e7lcgeDQn29WD78Wje+nmP2ZFERKSQUxFyNg17QcUWkJIAPw0GF5ulvWywDx89VB+Ab9cdYf62k+YGEhGRQk1FyNlYrdD5E3DzgoO/wrbpZifKd7fVLMmA26oCMOzH7Rw4G2dyIhERKaxUhJxR8WrQZphjefErEHfW3DwmeL5tDW6pUpSEZBv9p24mITnV7EgiIlIIqQg5q+aDoHQYJF52uRnqAdzdrHzSvQElArz480wcr8/dieFihwlFRCTvqQg5KzcPuGe8Y4b6XbNh3yKzE+W7kgHefPJwA6wWmL3lBDM2HjM7koiIFDIqQs4spAE0G+hY/nkIJEabm8cEzaoW44U7awIwfP4udp10vfdARETyjoqQs2vzChSpDLEnYflIs9OY4pnWVbmtZgmSU+30n7qFmMQUsyOJiEghoSLk7Dx94Z5PHMubvoIja8zNYwKr1cKHD9anbLAPRy4k8NLM7RovJCIiuUJFqCCo3Aoa9HQszx8EKYnm5jFBET9PIns0xMPNwuJdp/lq9WGzI4mISCGgIlRQ3Pkm+JeCCwdg1XtmpzFF/fLBvNapNgBjFu5h85FLJicSEZGCTkWooPApAp3edyyv/hhO7zA3j0l6Na/EXWFlSLUbDJy2hYvxyWZHEhGRAkxFqCAJvQdqd/5nhnqb651k0GKx8O59YVQu7sep6EQGz9iK3a7xQiIikjMqQgVNx7HgFQQno2D9JLPTmCLA24OJPRri5W5l1Z/niPz1gNmRRESkgFIRKmgCyzjGCwH88jZcPGhuHpPULhPIm13rAvDR8j9Zc+C8yYlERKQgUhEqiBo+BpVaQuoV+Ok5l5uh/qoHG5fngUblsBvw7PdRnIlxvW/TiYjIzVERKogsFuj8Mbh7w6FVsHWq2YlMM7pLXWqVDuB8XDKDpkeRarObHUlERAoQFaGCqlhVuO1Vx/KSVyH2jLl5TOLj6cbEHg3x93Jnw6GLfLDsT7MjiYhIAaIiVJDdMgDKhDvmIFv0otlpTFOlhD//u68eAJNW/sWKPa5ZCkVEJPtUhAoyN3e4ZwJY3GD3PNjzs9mJTHNXvTL0bl4JgCE/bOPYxQRzA4mISIGgIlTQlakHLZ51LC94Aa5cNjWOmV7pVIvwckFEX0lh4LQtJKXazI4kIiJOTkWoMGj9MhStCnGnYfkIs9OYxsvdjcgeDQny8WDb8WjeWbDH7EgiIuLkVIQKAw+ff2ao3zwFDv9hahwzlSviy0cPhQPwzdoj/LTtpMmJRETEmakIFRaVboVGvR3L8wdByhVT45jp9lqleKZNVQCG/bidv87FmZxIRESclYpQYdJuNASUcZxteuW7Zqcx1QvtatC0clHik230/24LV5I1XkhERK6lIlSYeAfBXR84lteMh1PbzM1jInc3K+O7N6C4vxf7zsTyxrydZkcSEREnpCJU2NS6C0K7gGFz2RnqryoZ6M0n3etjtcCszcf5YeMxsyOJiIiTUREqjDqOBe9gxx6htRPMTmOq5lWLM6RdDQDemLeT3SdjTE4kIiLOREWoMAooBe3fdiyvHAMX/jI3j8n6t6lGm5olSEq1M2DaFmITU8yOJCIiTkJFqLCq3wMqt4bURJeeoR7AarXw0YP1CQny5tD5eF7+cTuGC78fIiLyDxWhwipthnofOPw7bPk/sxOZqoifJxN6NMTDzcLCHaeZsuaw2ZFERMQJqAgVZkUrw+2vOZaXvgExp8zNY7KGFYrwSsfaALyzcA9RRy+ZnEhERMymIlTYNX0GQhpAUjQsHGp2GtP1aVGJjnVLk2IzGDB1C5fik82OJCIiJlIRKuzc3OGe8WB1h70/w+75ZicylcVi4X/316NSMV9ORify/A9bsds1XkhExFWpCLmC0mHQ4jnH8sKhcMW1DwkFenswsUcjvNytrNx3jkm/ufa36kREXJmKkKto9RIUqw5xZxzjhVxcaEggo7vUAeCDpftY89d5kxOJiIgZVIRchYf3PzPUR30LB38zN48TeLBxee5rWA67Ac9O38rZmESzI4mISD5TEXIlFZtD476O5Z+eg+QEc/OYzGKx8FbXutQsFcD5uCQGTY8i1WY3O5aIiOQjFSFX03YkBITApUOOs067OB9PNyY+2hA/TzfWH7rIh8v+NDuSiIjkIxUhV+MdCHd/6FheOwFORpmbxwlULeHPu/fVA2Diyr/4Ze8ZkxOJiEh+URFyRTU7Qp1uYNhh3iCwae6tzuEhPNasIgDPz9jG8UuufdhQRMRVqAi5qo7vgU8ROLMD1ow3O41TeO2u2oSXCyL6SgoDpkWRnKrxQiIihV2hL0I///wzNWvWpHr16nzxxRdmx3Ee/iWg/d9jhFa+C+cPmJvHCXi5uzHhkYYE+Xiw7dhl3lm4x+xIIiKSxwp1EUpNTWXIkCH88ssvREVFMXbsWC5cuGB2LOcR/jBUvR1sSfDTs2DXHpDyRX358MFwAKasOcyC7a49P5uISGFXqIvQhg0bqFOnDmXLlsXf35+OHTuydOlSs2M5D4sF7h4HHr5wZDVsmWJ2IqdwR+1SPN26KgAv/7idg+fiTE4kIiJ5xamL0KpVq+jcuTMhISFYLBbmzp17zTaRkZFUqlQJb29vmjZtyoYNG9JuO3nyJGXLlk27XrZsWU6cOJEf0QuOIhXh9r/PNL1sBMScNDePkxh6Zw2aVC5KXFIq/aduITHFZnYkERHJA05dhOLj4wkPDycyMjLD22fMmMGQIUMYMWIEW7ZsITw8nPbt23P27Nl8TlrANX0KyjaCpBhYMBQMTULq7mZlfPcGFPf3ZO/pWIbP22l2JBERyQNOXYQ6duzIW2+9xb333pvh7R9++CFPPvkkffr0ITQ0lMmTJ+Pr68tXX30FQEhISLo9QCdOnCAkJOS6z5eUlERMTEy6i0uwuv0zQ/2+BbB7rtmJnEKpQG8+frgBFgv8sOk4MzcdMzuSiIjkMqcuQplJTk5m8+bNtG3bNm2d1Wqlbdu2rF27FoAmTZqwc+dOTpw4QVxcHIsWLaJ9+/bXfcwxY8YQFBSUdilfvnyevw6nUaoO3DrEsbzwRUi4aG4eJ9GiWnGeb1sDgDfm7WTvaRcpxyIiLqLAFqHz589js9koVapUuvWlSpXi9OnTALi7u/PBBx9w2223Ub9+fV544QWKFSt23cd85ZVXiI6OTrscO+ZiewBaDYXiNSH+nGao/5eBt1WjVY0SJKbY6f/dFmITdQJKEZHCosAWoay65557+PPPPzlw4AD9+vXLdFsvLy8CAwPTXVyKu5fjEBkW2Pod/PWr2YmcgtVqYdxD9SkT5M3B8/EMm70DQ+OoREQKhQJbhIoXL46bmxtnzqSfF+rMmTOULl3apFSFQIWmEPGEY/mn5yA53tw8TqKonycTHmmIu9XCgu2n+L+1R8yOJCIiuaDAFiFPT08aNWrEihUr0tbZ7XZWrFhBs2bNTExWCLQdAYHl4PIR+PUds9M4jUYVizCsYy0A3lqwm63HLpsbSEREbppTF6G4uDi2bt3K1q1bATh06BBbt27l6NGjAAwZMoTPP/+cb775hj179vDMM88QHx9Pnz59TExdCHgFwN0fOZbXTYQTm83N40T63lqZDnVKk2IzGDB1C5cTks2OJCIiN8Gpi9CmTZto0KABDRo0ABzFp0GDBgwfPhyAhx56iPfff5/hw4dTv359tm7dyuLFi68ZQC05UONOCHtAM9T/h8Vi4b0H6lGxmC8nLl9hyA/bsNs1XkhEpKCyGBr1eV0xMTEEBQURHR3tegOnAeLPw4QIuHIRbn8dWr1odiKnsetkNPdOXENyqp2XOtSkf5tqZkcSEZG/Zefvt1PvERKT+RWHDu86ln97D879aW4eJ1InJIhR99QB4P0l+1h3UJP5iogURCpCGYiMjCQ0NJSIiAizo5iv3oNQrR3YkjVD/X88HFGebg3KYjdg0PQozsYmmh1JRESySYfGMuHyh8auunwUIm+BlHi464N/vl4vJCSn0jVyNX+eiaNZlWJ890RT3KwWs2OJiLg0HRqT3BVcwfGVeoBlIyH6RKabuxJfT3cm9miIr6cbaw9e4KNlOnwoIlKQqAhJ1kQ8AeUiIDkWFgzRDPX/Uq1kAGO6hQEw4dcD/LrvrMmJREQkq1SEJGvSZqj3gD8Xw84fzU7kVLrUL8ujt1QA4PkZWzlx+YrJiUREJCtUhCTrStZ2TMwKsOhlzVD/H2/cHUpY2SAuJ6QwYOoWklM1sFxExNnlqAgdO3aM48ePp13fsGEDgwcP5rPPPsu1YOKkbh0CJWpDwnlY8qrZaZyKl7sbE3s0JNDbna3HLjNm0R6zI4mIyA3kqAg98sgj/PqrY2by06dP065dOzZs2MBrr73G6NGjczWgOBl3T7jnE8AC26bDgeVmJ3Iq5Yv68sGD9QH4evVhFu44ZW4gERHJVI6K0M6dO2nSpAkAP/zwA3Xr1mXNmjVMnTqVKVOm5GY+cUblm0DTpxzLPz0PSXHm5nEy7UJL8VSrKgC8NGs7h87Hm5xIRESuJ0dFKCUlBS8vLwCWL1/OPffcA0CtWrU4dUr/AnYJt78BQRUg+ij8+rbZaZzO0PY1iahUhLikVJ75bjOJKTazI4mISAZyVITq1KnD5MmT+f3331m2bBkdOnQA4OTJkxQrVixXA5pBZ5bOAi//f81QPwmObzI3j5PxcLMyvntDivl5svd0LCPm7TI7koiIZCBHReh///sfn376KW3atKF79+6Eh4cDMH/+/LRDZgXZgAED2L17Nxs3bjQ7inOr3hbqPQQYMH8QpCabnciplA7y5uOHG2CxwIxNx5i1+fiN7yQiIvkqx1Ns2Gw2YmJiKFKkSNq6w4cP4+vrS8mSJXMtoJk0xUYWxF+AyAhIuABtXoU2L5udyOl8vHw/Hy3/E28PK3MHtKBWaX2WRETyUp5PsXHlyhWSkpLSStCRI0cYN24c+/btKzQlSLLIrxh0fM+xvGosnN1rbh4nNOj2arSsXpzEFDv9p24hLinV7EgiIvK3HBWhLl268H//938AXL58maZNm/LBBx/QtWtXJk2alKsBpQCoex9Ubw/2FM1QnwGr1cK4h+pTOtCbg+fieWX2DjTXsYiIc8hREdqyZQstW7YEYNasWZQqVYojR47wf//3f3zyySe5GlAKAIvFMSu9pz8cWw8bvzA7kdMp5u9FZI8GuFst/LTtJN+tO2J2JBERIYdFKCEhgYCAAACWLl1Kt27dsFqt3HLLLRw5ol/wLim4PLQd6VheMQouHzM1jjNqVLEoL3eoBcCbP+9h+/HL5gYSEZGcFaFq1aoxd+5cjh07xpIlS7jzzjsBOHv2rAYVu7LGfaH8LZAcpxnqr+OJlpW5M7QUyTbHeKHohBSzI4mIuLQcFaHhw4czdOhQKlWqRJMmTWjWrBng2DvUoEGDXA0oBYjV6pih3s0T9i+FHbPMTuR0LBYLYx8Ip0JRX45fusILM7dit6swioiYJUdF6P777+fo0aNs2rSJJUuWpK2/4447+Oijj3ItnBRAJWpAq5ccy4tfdny9XtIJ8vFgYo+GeLpbWb7nLJ/9ftDsSCIiLitHRQigdOnSNGjQgJMnT6bNRN+kSRNq1aqVa+GkgGrxHJQMdZxbaPEws9M4pbplgxjRORSAsUv2sf6gCqOIiBlyVITsdjujR48mKCiIihUrUrFiRYKDg3nzzTex66vT4u4J90wAixV2/AD7l5mdyCk90qQCXeuHYLMbDJoexbnYJLMjiYi4nBwVoddee40JEybw7rvvEhUVRVRUFO+88w7jx4/njTfeyO2M+U5zjeWCco2g6TOO5Z8GQ1KsqXGckcVi4e17w6hW0p+zsUk8930UNo0XEhHJVzmaYiMkJITJkyenzTp/1bx58+jfvz8nTpzItYBm0hQbNyk5HibeApePQpOnoNN7ZidySvvPxHLPhNVcSbHx7O3VGHJnTbMjiYgUaHk+xcbFixczHAtUq1YtLl68mJOHlMLI0w/uHudY3vAZHNtgahxnVb1UAGO6hQEw/tcD/PbnOZMTiYi4jhwVofDwcCZMmHDN+gkTJlCvXr2bDiWFSLU7IPwRwIB5AyFV42Ay0rVBWR5pWgHDgMHfR3Hy8hWzI4mIuIQcHRr77bffuOuuu6hQoULaOYTWrl3LsWPHWLhwYdr0GwWdDo3lkoSLENkE4s9B62Fw2ytmJ3JKiSk27p+8hp0nYmhYIZgZTzXDwy3HX+wUEXFZeX5orHXr1vz555/ce++9XL58mcuXL9OtWzd27drFt99+m6PQUoj5Fv1nhvrfP4Cze8zN46S8PdyY+EgjArzd2XL0Mu8u2mt2JBGRQi9He4SuZ9u2bTRs2BCbzZZbD2kq7RHKRYYB07vDn4ugbGPouxSsbmanckpLdp3mqW83AzD50YZ0qFvG5EQiIgVLnu8REsm2tBnqA+DEJsfgaclQ+zqlebJlZQBenLmdw+fjTU4kIlJ4qQhJ/gkqC+1GOZZXvAmXjpibx4m91KEWjSsWITYplf5Tt5CYUjj2soqIOBsVIclfjfpAheaQEg8/P68Z6q/Dw83K+EcaUNTPk92nYhj10y6zI4mIFEru2dm4W7dumd5++fLlm8kirsBqhXs+gUkt4K8VsH0GhD9sdiqnVCbIh48frs9jX21g+oZjRFQqSreG5cyOJSJSqGRrj1BQUFCml4oVK/LYY4/lVVYpLIpXh9ZXZ6gfBnE6geD1tKxegmdvrw7Aa3N28ucZTVUiIpKbcvVbY4WNvjWWh2wp8NltcGYH1L0f7v/S7EROy2Y36PXVBv44cJ6qJfyYP/BW/LyytTNXRMSl6FtjN0mTruYDNw/HITKLFXbOgj+XmJ3IablZLYx7uD6lAr3461w8r8zegf79IiKSO1SEMjBgwAB2797Nxo0bzY5SuJVtCLf0dyz//Dwkxpibx4kV9/diwiMNcbNamL/tJN+tP2p2JBGRQkFFSMx122tQpBLEnIAVo8xO49QiKhXl5Q6Omenf/Gk3249fNjeQiEghoCIk5vL0hc4fO5Y3fgFH15mbx8k92bIK7UJLkWyz03/qFqITUsyOJCJSoKkIifmqtIEGjzqW5w+ClERT4zgzi8XC+w+EU76oD8cvXeGFmds0XkhE5CaoCIlzuPMt8CsJ5/+E3983O41TC/LxYOIjjfB0s7J8zxk+W3XQ7EgiIgWWipA4B58i0GmsY/mPj+D0TnPzOLmwckEM7xwKwHtL9rHh0EWTE4mIFEwqQuI8QrtArbvBnuo4RGbX/FqZ6dG0AveEh2CzGwyavoXzcUlmRxIRKXBUhMR5WCzQ6X3wCoKTW2D9ZLMTOTWLxcKYbmFULeHHmZgkBn+/FZtd44VERLJDRUicS2AZuHO0Y/mXt+DSYVPjODs/L3cmPdoIHw83/jhwnk9W7Dc7kohIgaIiJM6nwWNQ8VZISYCfntMM9TdQo1QAb99bF4BPftnPqj81d5uISFapCInzuTpDvbs3HFwJ26abncjpdWtYju5NymMYMHjGVv46F2d2JBGRAkFFSJxTsarQZphjefErEHfW3DwFwIjOdagTEsjF+GS6Rq7WniERkSxQERLn1WwQlK4HiZdh0Utmp3F63h5uTOnThEYVixCbmErvrzfw1R+HdMJFEZFMqAiJ83Jzh3vGg8UNds2BvQvNTuT0SgR4Me3JptzfqBx2A0b/vJtXZu8gOdVudjQREaekIpSByMhIQkNDiYiIMDuKhNSH5gMdywuGQGK0qXEKAi93N8beX4/XOtXGaoHvNx7j0S/Wc0HnGRIRuYbF0H7z64qJiSEoKIjo6GgCAwPNjuO6Uq7ApOZw8SA0fhzu/sjsRAXGr3vP8uz0KGKTUikb7MOXvRtTq7Q+yyJSuGXn77f2CInz8/D5Z4b6TV/B4dXm5ilAbqtVktn9m1OxmC8nLl/hvolrWLrrtNmxRESchoqQFAyVW0HDxxzLPz2rGeqzoXqpAOb2b0HzqsWIT7bx1Hebifz1gAZRi4igIiQFSbs3wb80XDgAv/3P7DQFShE/T755vAk9b6mIYcDYJfsYPGMriSmaz01EXJuKkBQcPsFw1/uO5dUfw+kdpsYpaDzcrLzZtS5vdqmDm9XCvK0neeizdZyN0d41EXFdKkJSsNTuDLXvAcMG8waCLdXsRAVOz2aV+PbxJgT5eLDt2GXumbCa7ccvmx1LRMQUKkJS8HQaC95BcGorrJtodpoCqXm14swb0IJqJf05HZPIA5PX8tO2k2bHEhHJdypCUvAElIY733Is//qO42v1km2Vivsxu39zbqtZgqRUO4OmR/HB0n3Y7RpELSKuQ0VICqYGPR3fJEu9ohnqb0Kgtwdf9IqgX6sqAIz/5QDPTN1MfJIOOYqIa1ARkoLJYnGcW8jdBw6tgqjvzE5UYLlZLbzaqTZj76+Hp5uVJbvOcP/ktRy/lGB2NBGRPKciJAVX0Spw26uO5aWvQaxOFHgzHmhcnun9mlLc35M9p2LoGrmaTYcvmh1LRCRPqQhJwXZLfyhT3zEH2cIXzU5T4DWqWJR5A2+ldplAzscl0/3zdczcdMzsWCIieUZFSAq2f89Qv2c+7PnJ7EQFXtlgH358phkd6pQmxWbw4qztvL1gNzYNohaRQkhFSAq+MvWgxXOO5QVD4cplU+MUBr6e7kzs0ZBn76gOwOe/H6LvNxuJSUwxOZmISO5SEZLCofXLUKwaxJ2GZcPNTlMoWK0WhrSrwfjuDfByt7Jy3zm6TVzD4fPxZkcTEck1KkJSOHh4Q+dPHMtbvoFDv5ubpxDpHB7CrKebUzrQmwNn4+gSuZo1B86bHUtEJFeoCEnhUakFNOrjWP7pWUi5Ym6eQiSsXBDzB7YgvHww0VdS6PnVBr5de9jsWCIiN01FSAqXdqMgoIzjbNMr3zU7TaFSMtCbGf1uoWv9EGx2gzfm7eL1uTtIsdnNjiYikmMqQhmIjIwkNDSUiIgIs6NIdnkHwV0fOpbXjIeTW02NU9h4e7jx0UP1ealDTSwW+G7dUR77cgOX4pPNjiYikiMWw9DcBNcTExNDUFAQ0dHRBAYGmh1HsuOHXrB7LpSuB0/+6viaveSqZbvPMPj7KOKTbVQs5ssXjzWmeqkAs2OJiGTr77f2CEnh1GkseAfD6e2wdoLZaQqldqGl+LF/c8oV8eHIhQTunbiGX/eeNTuWiEi2qAhJ4eRfEtq/41heOQYu/GVunkKqVulA5g1oQZPKRYlLSuXxbzby2aq/0I5mESkoVISk8Kr/CFRpA6mJmqE+DxXz9+K7vk15OKI8hgHvLNzL0JnbSUq1mR1NROSGVISk8LJY4O5x4OELh393nF9I8oSnu5Ux3cIY0TkUqwV+3HKc7p+t41xsktnRREQypSIkhVvRynDba47lpcMh5pS5eQoxi8VCnxaVmdKnCQHe7mw5epkuE/5g54los6OJiFyXipAUfrc8AyENISkaFg41O02h16pGCeYOaEGV4n6cjE7kgclrWbRDBVREnJOKkBR+VjfHDPVWd9j7M+yeZ3aiQq9qCX/m9G9By+rFuZJi45mpW/hkxX4NohYRp6MiJK6hdF249XnH8sIX4colc/O4gCBfD77uHUGfFpUA+HDZnwycHsWVZA2iFhHnoSIkrqPlUChWHeLOwNLXzU7jEtzdrIzoXIcx3cJwt1pYsP0UD366llPRmgdORJyDipC4Dg9vxyEygKjv4OBKU+O4ku5NKjD1iaYU9fNkx4lo7pmwmqij2isnIuZTERLXUrEZRDzhWP7pOUhOMDePC2lapRjzBrSgZqkAzsUm8dBn65gbdcLsWCLi4lSExPXcMQICy8Klw7DyHbPTuJTyRX35sX9z2tYuSXKqncEztvK/xXux2zWIWkTMoSIkrsc78J8Z6tdGwokt5uZxMf5e7nzWszH921QFYNLKv+j37SbiklJNTiYirkhFSFxTzQ5Q9z4w7DD/WbClmJ3IpVitFl7qUItxD9XH093K8j1nuW/iGo5d1KFKEclfKkLiujr8D3yKwJkdsOYTs9O4pK4NyjKj3y2UCPBi35lY7pnwB+sPXjA7loi4EBUhcV3+JaDDu47llf+D8/vNzeOiGlQowvyBLQgrG8SlhBR6fLGe6RuOmh1LRFyEipC4tnoPQdXbwZbkOERmt5udyCWVCfLhh6eacVe9MqTaDV6ZvYOR83eRatPPQ0TyloqQuLa0Ger94Oga2DLF7EQuy8fTjQndGzCkXQ0Apqw5TJ8pG4lO0PgtEck7KkIiRSrCHW84lpeNgJiT5uZxYRaLhWfvqM6kHg3x8XDj9/3nuXfiav46F2d2NBEppFSERACa9IOyjSEpBha8AJoc1FQdw8ow65lmhAR5c/B8PF0jV7Pqz3NmxxKRQkhFSAT+NUO9B+xbCLvmmJ3I5dUJCWLewFtpVLEIsYmp9P56A1/9cUgz2ItIrlIRErmqVCi0HOJYXvQSJFw0N49QIsCLaU825f5G5bAbMPrn3bwyewfJqRpELSK5Q0VI5N9avgDFa0L8Oc1Q7yS83N0Ye389XutUG4sFvt94jEe/XM+FuCSzo4lIIaAilIHIyEhCQ0OJiIgwO4rkN3cv6DIBsMDWqfDXL2YnEhyDqJ9sVYWvekUQ4OXOhkMX6RK5mr2nY8yOJiIFnMXQAffriomJISgoiOjoaAIDA82OI/lp4Yuw4TMIrgD914Gnn9mJ5G/7z8TyxP9t4siFBPw83Rj3cAPahZYyO5aIOJHs/P3WHiGRjNwxHALLweWj8KtmqHcm1UsFMLd/C5pVKUZ8so1+325i4soDGkQtIjmiIiSSEa8A6DzOsbxuIpzYbGocSa+Inyf/17cJPW+piGHAe4v38fyMrSSm2MyOJiIFjIqQyPVUbwdhDzpmqJ83CFKTzU4k/+LhZuXNrnV5s0sd3KwW5m49yUOfreNsTKLZ0USkAFEREslMh3fBtxic3QWrPzY7jWSgZ7NKfPt4E4J8PNh27DL3TFjNjuPRZscSkQJCRUgkM37F/pmhftV7cO5Pc/NIhppXK868AS2oVtKf0zGJPPDpGn7apqlSROTGVIREbiTsAajWDmzJ8JNmqHdWlYr7Mbt/c9rULEFiip1B06P4cOk+7HYNohaR61MRErkRiwXu/gg8/eHoWtj0pdmJ5DoCvT34slcE/VpVAeCTXw7Qf+oWEpJTTU4mIs5KRUgkK4LLwx0jHMvLR0L0cVPjyPW5WS282qk2Y++vh6eblcW7TnPfpLWcuHzF7Ggi4oRUhESyKqIvlGsCyXHw8xDNUO/kHmhcnun9mlLc35M9p2LoMuEPNh/R/HEikp6KkEhWXZ2h3s0T9i+BnT+anUhuoFHFoswbeCu1ywRyPi6Z7p+tZ+amY2bHEhEnoiIkkh0la0HLoY7lRS9rhvoCoGywD7OebkaHOqVJttl5cdZ23l6wG5sGUYsIKkIi2Xfr81CiNiSch8WvmJ1GssDPy52JPRry7O3VAPj890M88c1GYhJTTE4mImZTERLJLndPxyEyLLD9e9i/3OxEkgVWq4Uhd9ZkfPcGeLlb+XXfObpNXMPh8/FmRxMRE6kIieRE+Qho+rRj+efnISnO3DySZZ3DQ5j1dHNKB3pz4GwcXSeuZs2B82bHEhGTqAiJ5NTtr0NQBYg+Cr+8ZXYayYawckHMH9iC8PLBXE5IoedXG/h23RGzY4mICVSERHLKyx86f+RYXj8Zjm00N49kS8lAb2b0u4Wu9UOw2Q3emLuTN+buJMWmM4eLuBIVIZGbUa0t1HsYMGC+ZqgvaLw93Pjoofq81KEmFgt8u+4Ivb7awOUE/RxFXIWKkMjN6jAGfIvDuT3wx0dmp5Fsslgs9G9Tjc96NsbP0401f12gS+RqDpyNNTuaiOQDFSGRm+VbFDr+z7G8aiyc3WtuHsmRdqGl+LF/c8oV8eHIhQTujVzDr3vPmh1LRPKYipBIbqh7H9ToAPYUxyEyu83sRJIDtUoHMm9AC5pUKkpsUiqPf7ORz1cdxNB0KiKFloqQSG6wWOCuD8AzAI5vgI1fmJ1IcqiYvxffPdGUhyPKYxjw9sI9vDhrO0mpKrcihZGKkEhuCSoHba/OUD8KLmtOq4LK093KmG5hjOgcitUCszYf55HP13MuNsnsaCKSy1SERHJT475QoRmkxDtOtKhDKgWWxWKhT4vKTOnThABvdzYfuUSXCX+w62S02dFEJBepCInkJqsVOn/imKH+wDLYMdPsRHKTWtUowdwBLahS3I+T0YncP2kti3eeMjuWiOQSFSGR3FaiBrR+ybG86GWI1/QNBV3VEv7M6d+CltWLcyXFxtPfbeGTFfs1iFqkEFAREskLzZ+DknXgykXNUF9IBPl68HXvCHo3rwTAh8v+ZND0KK4kaxC1SEGmIiSSF9w9oct4sFhhxw+wf5nZiSQXuLtZGXlPHcZ0C8PdauHn7ad48NO1nI5ONDuaiOSQipBIXinbCG7p71j+aTAk6UzFhUX3JhWY+kRTivp5suNENJ0n/EHU0UtmxxKRHFAREslLt70KwRUh5jisGG12GslFTasUY96AFtQsFcC52CQe+mwdc6NOmB1LRLJJRUgkL3n6QeePHcsbPoej683NI7mqfFFffuzfnLa1S5KcamfwjK38b/Fe7HYNohYpKFSERPJa1dugfg/+maFeJ+UrTPy93PmsZ2OeaVMVgEkr/6Lft5uJS0o1OZmIZIWKkEh+uPMt8CsJ5/fB7x+YnUZymdVq4eUOtfjooXA83a0s33OG+yau4djFBLOjicgNqAiJ5AffotDpPcfy7x/Cmd3m5pE8cW+DcszodwslArzYdyaWLpGrWX/wgtmxRCQTKkIZiIyMJDQ0lIiICLOjSGES2hVqdtIM9YVcgwpFmD+wBXXLBnIxPpkeX6zn+w1HzY4lItdhMXRq1OuKiYkhKCiI6OhoAgMDzY4jhUHMSYhsCkkx0OFduOUZsxNJHrmSbGPorG0s2O6YjqNPi0q81qk27m7696dIXsvO32/9HymSnwJDoN0ox/KK0XDpiLl5JM/4eLoxoXsDhrSrAcDXqw/TZ8pGohNSTE4mIv+mIiSS3xr2hootICUBfh6sGeoLMYvFwrN3VGdSj4b4eLjx+/7z3DtxNQfPxZkdTUT+piIkkt/SZqj3gr9+gW3fm51I8ljHsDLMeqYZIUHeHDwfT9fI1fy+/5zZsUQEFSERcxSvBm1ediwveQXi9EexsKsTEsS8gbfSsEIwMYmp9P56I1+vPqQZ7EVMpiIkYpbmz0LpMLhyCRa/bHYayQclAryY3u8W7mtYDpvdYNRPu3l1zg6SU+1mRxNxWSpCImZx84B7/p6hfuePsG+x2YkkH3i5u/H+A/V4rVNtLBaYvuEYj365novxyWZHE3FJKkIiZgppAM0GOJYXDIHEGHPzSL6wWCw82aoKX/WKIMDLnQ2HLnLPhD/Ye1o/f5H8piIkYrY2r0KRyhBzAlaMMjuN5KPbapVkdv/mVCzmy/FLV7hv4hqW7T5jdiwRl6IiJGI2T99/Zqjf+AUcWWtuHslX1UsFMLd/C5pVKUZ8so1+325i4soDGkQtkk9UhEScQZXW0KCnY3n+IEhJNDeP5Ksifp78X98mPHpLBQwD3lu8j+dnbCUxRdOwiOQ1FSERZ3Hnm+BfCi7sh1VjzU4j+czDzcpbXcN4s0sd3KwW5m49ycOfreNsjEqxSF5SERJxFj5FoNPfBWj1ODi909Q4Yo6ezSrx7eNNCPLxYOuxy9wzYTU7jkebHUuk0FIREnEmoV2g1t1gT9UM9S6sebXizBvQgmol/Tkdk8gDn67h5+0nzY4lUiipCIk4m07vg1cQnNwC6yaZnUZMUqm4H7P7N6dNzRIkptgZOC2KD5fuw27XIGqR3KQiJOJsAss4xgsB/PIWXDxkbh4xTaC3B1/2iuDJlpUB+OSXA/SfuoWE5FSTk4kUHipCIs6o4WNQqSWkXtEM9S7OzWrhtbtCGXt/PTzdrCzedZr7J63lxOUrZkcTKRRUhESckcXiOLeQuzccXAlbp5mdSEz2QOPyTHuyKcX9Pdl9KoYuE/5g85GLZscSKfBUhEScVbGq0OYVx/KSVyHurLl5xHSNKxVl7oAW1C4TyPm4ZLp/tp5Zm4+bHUukQFMREnFmzQZC6XqQeBkWvmh2GnEC5Yr4MuvpZnSoU5pkm52hM7fxzsI92DSIWiRHVIREnJmbO3SZABY32D0X9i4wO5E4AT8vdyb2aMizt1cD4LNVB3nim43EJqaYnEyk4FEREnF2ZcKh+SDH8oIXIFEn1xOwWi0MubMm47s3wMvdyq/7znHvxDUcuRBvdjSRAkVFSKQgaDMMilaF2FOwbITZacSJdA4PYebTzSgV6MWBs3F0iVzNmr/Omx1LpMBQERIpCDx84J5PHMubv4bDf5ibR5xKvXLBzB94K+Hlg7mckMJjX27g23VHzI4lUiCoCIkUFJVuhYa9HMvzn9UM9ZJOqUBvZvS7ha71Q0i1G7wxdydvzN1Jis1udjQRp6YiJFKQtBsN/qXh4l/w2//MTiNOxtvDjY8eqs9LHWpiscC3647Q66sNXE5INjuaiNNSERIpSHyC4a4PHMurP4ZT202NI87HYrHQv001PuvZGD9PN9b8dYEukas5cDbW7GgiTklFSKSgqX23Y5Z6wwbzB4JN807JtdqFluLH/s0pV8SHIxcSuDdyDb/u00k5Rf5LRUikIOo4FryD4NQ2WBdpdhpxUrVKBzJvQAuaVCpKbFIqfads5IvfD2Jo7jqRNCpCIgVRQCm4823H8q/vwIW/zM0jTquYvxffPdGUhyPKYzfgrQV7eHHWdpJSbWZHE3EKKkIiBVWDR6Fya0hN1Az1kilPdytjuoUxonMoVgvM2nycRz5fz7nYJLOjiZhORUikoEqbod4HDq2CqG/NTiROzGKx0KdFZab0aUKAtzubj1yia+Rqdp+MMTuaiKlUhEQKsqKV4fbXHMtLXofY0+bmEafXqkYJ5g5oQeXifpy4fIX7Jq1h8U59bsR1qQiJFHRNn4Ey9SEpWjPUS5ZULeHP3P4taFm9OFdSbDz93WbGr9ivQdTiklSERAq6qzPUW91hz3zY85PZiaQACPL14OveEfRuXgmAD5b9ybPfb+VKsgZRi2uxGPonwHXFxMQQFBREdHQ0gYGBZscRydyK0fD7B+BXEhr3gcCyEFQWAss5/usVYHZCcVLTNxzljbk7SbUbhJUN4vPHGlM6yNvsWCI5lp2/3ypCmVARkgIlJREm3woX9md8u3fQP6XovyUp8O+Lh/74uap1By/wzHebuZSQQskALz57rDH1ywebHUskR1SEcomKkBQ4cWcd3x67fAxiTkD0CYg5DonRWbu/X4m/S1K5f5Wlf10PKOM4FCeF0rGLCTzxzSb2nYnF093K2Pvr0aV+WbNjiWSbilAuURGSQiMp9p9SFH0ifUm6ej0l4caPY7E6ylBGJenqHia/EmDV8MOCKi4plcHfR7F8j2M6jv5tqjL0zppYrRaTk4lknYpQLlEREpdhGHDlEkQf/7skHf9XWbp6/STYU278WG6eEBiS+WE4nyKO8yCJU7LZDd5fuo9JKx1nLG8XWoqPHqqPv5f2BkrBoCKUS1SERP7Fbof4sxnsWfpXaYo9BWThV4qH3/VL0tU9TF7+ef6SJHNzoo7z8o87SE61U7NUAI/eUoFAHw/HxduDIB/3tGVvDzez44qkURHKJSpCItlkS3GUoYxK0tXylHA+a4/lHXz9sUpXr7t75enLEYg6eol+326+4XQcnu7Wa8pRkI8HgT7uBHo7ylPQ3+uvrgv6u1QFeLvj4abDqZJ7VIRyiYqQSB5IueI4zJZRSbp6PSmrg7tLXn+sUlBZ8C+twd254FT0FT797SCnoxOJSUwh+koKMYkpxFxJJSYxJVemufPzdEsrUIE+7v8qTR4Eerun2xP139sDvNw1hknSURHKJSpCIiZJjLlOSfrXGKbUxBs/jsXNMbg7s8NwfiU0Xukm2O0GccmpxFxxFKN/SlIKMYl/X//3ur/LU8wVR6GKz4UTOFosEOB1oz1R7v8s/6dQ+Xi4YdFnoFDJzt9v/VNJRJyPd6DjUrJ2xrcbBiRcvP5YpZirg7tT/14+fv3ncvNyDO7O7DCcd7DK0nVYrRZHqfD2gCLZv3+qzU5sYuo/e5qu/Hv5nz1P/y5Y0X+XrJgrKSSl2jEMHNcTU4Er2c7gbrWk7XlKX5SuX6j+Xbi83DU+qiDTHqFMaI+QSAFmtznOq3S9sUoxJ/6epDYLvwI9/TM/ZUBQWfD0y/OXJNdKTLGlO0z336IU85/DeP8ULEe5stlv/k+gl7v1XwXKPdPxUP/dYxXg7Y67xkflOh0ayyUqQiKFXGqyY3B3ZofhEi5k7bF8itz4zN3unnn7eiRbDMMgIdmWfq9Tuj1Pqf86zHftHqvYxNRcyeHv5Z5uT1Nme6LSFSwfD/w9NT4qIypCuURFSERITnAcZrveYbjo45Acm7XH8i+V+SkDAkqDVYdZCgqb3SAuKfVfe6HS75nKeJzUP4f5EnJhfJTVAgH/3fOU0YDzawagO7b19rAWyvFRKkK5REVIRLIkMTrzUwbEnMj64O7AkBucubu4xisVEil/j4/6d1GKzmBA+dXDfOnK1pUUkm32m87g4WZJK0UBWTq0l34clae7cx7WUxHKJSpCIpIrDMNxiC2zUwbEnAAjC3sI3LwyH6sUWNYxwa7KUqGXmGL7V4FK/c9hvX+Nk8qgYMUkpubK+ChvD+s1pzq43nio/xasAG8P3PLosJ6KUC5RERKRfGO3QdyZzM/cHXeGrA3uDrjxmbs9ffP8JYnzMgyD+GTbP6XpenueEq+9PeZKCrFJuTM+KsDLnSBfD35/6bZcPUSnr8+LiBQ01quHxUKAiIy3SU2G2JOZH4a7ctExZuncXsflenyKXr8kBZWFgBAN7i7ELBYL/l7u+Hu5ExLsk+372+wGcYn/PW/U9U6BcG3BupLi2PsZm5SKxYKp45Rcogjde++9rFy5kjvuuINZs2aZHUdEJGfcPaFIJcflepITMh+rFH0ckuMchenKRTi94zoPZHEM7v73t948fMDq/vfF7Z9lN4/01zPaxprRNjl5DOcck+Jq3KwWgnw9CPL1yNH9k1PtaQUqNwaN3wyXODS2cuVKYmNj+eabb7JVhHRoTEQKHcNwDO7O9MzdJ8CW+dxi5rFks0xlVK4yud3tBrdb3f4uZJk8fl48hsWqcV/ZoENj/9GmTRtWrlxpdgwREfNZLOAT7LiUqpPxNoYB8efTl6SYk2BLdpyt25bi+K/d9vd/UzO4nnKD21PBlpr5/TMO9/djX+/2QixbZcrt72KYWRlz/9djXOd2t+vdnpuP4eHY82gS04vQqlWrGDt2LJs3b+bUqVPMmTOHrl27ptsmMjKSsWPHcvr0acLDwxk/fjxNmjQxJ7CISGFnsYB/CcclpIF5OW5UpG5YpjK65MVj2P5VDjMriDcokLYbFLyr2xc27j7w+mnznt60Z/5bfHw84eHhPP7443Tr1u2a22fMmMGQIUOYPHkyTZs2Zdy4cbRv3559+/ZRsmRJAOrXr09q6rUfjqVLlxISEpLnr0FERPKA1c1xwcvsJPnLbs+kfGWlTF2vzGXxMdIeJy/3+P3r4u5t6tttehHq2LEjHTt2vO7tH374IU8++SR9+vQBYPLkySxYsICvvvqKYcOGAbB169ZcyZKUlERS0j/HxWNiYnLlcUVERLLMagWrJ6Bv7eUHpx5+n5yczObNm2nbtm3aOqvVStu2bVm7dm2uP9+YMWMICgpKu5QvXz7Xn0NERESch1MXofPnz2Oz2ShVqlS69aVKleL06awfT2zbti0PPPAACxcupFy5ctctUa+88grR0dFpl2PHjt1UfhEREXFuph8ayw/Lly/P0nZeXl54ebnYsWgREREX5tR7hIoXL46bmxtnzpxJt/7MmTOULl3apFQiIiJSWDh1EfL09KRRo0asWLEibZ3dbmfFihU0a9bMxGQiIiJSGJh+aCwuLo4DBw6kXT906BBbt26laNGiVKhQgSFDhtCrVy8aN25MkyZNGDduHPHx8WnfIhMRERHJKdOL0KZNm7jtttvSrg8ZMgSAXr16MWXKFB566CHOnTvH8OHDOX36NPXr12fx4sXXDKAWERERyS6XmGsspzTXmIiISMGTnb/fTj1GSERERCQvqQhlIDIyktDQUCIiIsyOIiIiInlIh8YyoUNjIiIiBY8OjYmIiIhkgYqQiIiIuCwVIREREXFZpp9HyJldHT4VExNjchIRERHJqqt/t7MyDFpFKBOxsbEAlC9f3uQkIiIikl2xsbEEBQVluo2+NZYJu93OyZMnCQgIwGKx5Opjx8TEUL58eY4dO6ZvpN2A3qus03uVdXqvskfvV9bpvcq6vHqvDMMgNjaWkJAQrNbMRwFpj1AmrFYr5cqVy9PnCAwM1P8oWaT3Kuv0XmWd3qvs0fuVdXqvsi4v3qsb7Qm6SoOlRURExGWpCImIiIjLUhEyiZeXFyNGjMDLy8vsKE5P71XW6b3KOr1X2aP3K+v0XmWdM7xXGiwtIiIiLkt7hERERMRlqQiJiIiIy1IREhEREZelIiQiIiIuS0UoD0VGRlKpUiW8vb1p2rQpGzZsyHT7mTNnUqtWLby9vQkLC2PhwoX5lNR82XmvpkyZgsViSXfx9vbOx7TmWbVqFZ07dyYkJASLxcLcuXNveJ+VK1fSsGFDvLy8qFatGlOmTMnznM4gu+/VypUrr/lcWSwWTp8+nT+BTTRmzBgiIiIICAigZMmSdO3alX379t3wfq74Oysn75Wr/s6aNGkS9erVSztZYrNmzVi0aFGm9zHjM6UilEdmzJjBkCFDGDFiBFu2bCE8PJz27dtz9uzZDLdfs2YN3bt3p2/fvkRFRdG1a1e6du3Kzp078zl5/svuewWOs5CeOnUq7XLkyJF8TGye+Ph4wsPDiYyMzNL2hw4d4q677uK2225j69atDB48mCeeeIIlS5bkcVLzZfe9umrfvn3pPlslS5bMo4TO47fffmPAgAGsW7eOZcuWkZKSwp133kl8fPx17+Oqv7Ny8l6Ba/7OKleuHO+++y6bN29m06ZN3H777XTp0oVdu3ZluL1pnylD8kSTJk2MAQMGpF232WxGSEiIMWbMmAy3f/DBB4277ror3bqmTZsaTz31VJ7mdAbZfa++/vprIygoKJ/SOS/AmDNnTqbbvPTSS0adOnXSrXvooYeM9u3b52Ey55OV9+rXX381AOPSpUv5ksmZnT171gCM33777brbuPLvrH/Lynul31n/KFKkiPHFF19keJtZnyntEcoDycnJbN68mbZt26ats1qttG3blrVr12Z4n7Vr16bbHqB9+/bX3b6wyMl7BRAXF0fFihUpX758pv/CcHWu+rm6GfXr16dMmTK0a9eO1atXmx3HFNHR0QAULVr0utvos+WQlfcK9DvLZrPx/fffEx8fT7NmzTLcxqzPlIpQHjh//jw2m41SpUqlW1+qVKnrjjc4ffp0trYvLHLyXtWsWZOvvvqKefPm8d1332G322nevDnHjx/Pj8gFyvU+VzExMVy5csWkVM6pTJkyTJ48mR9//JEff/yR8uXL06ZNG7Zs2WJ2tHxlt9sZPHgwLVq0oG7dutfdzlV/Z/1bVt8rV/6dtWPHDvz9/fHy8uLpp59mzpw5hIaGZritWZ8pzT4vBU6zZs3S/YuiefPm1K5dm08//ZQ333zTxGRSkNWsWZOaNWumXW/evDl//fUXH330Ed9++62JyfLXgAED2LlzJ3/88YfZUZxeVt8rV/6dVbNmTbZu3Up0dDSzZs2iV69e/Pbbb9ctQ2bQHqE8ULx4cdzc3Dhz5ky69WfOnKF06dIZ3qd06dLZ2r6wyMl79V8eHh40aNCAAwcO5EXEAu16n6vAwEB8fHxMSlVwNGnSxKU+VwMHDuTnn3/m119/pVy5cplu66q/s67Kznv1X670O8vT05Nq1arRqFEjxowZQ3h4OB9//HGG25r1mVIRygOenp40atSIFStWpK2z2+2sWLHiusdGmzVrlm57gGXLll13+8IiJ+/Vf9lsNnbs2EGZMmXyKmaB5aqfq9yydetWl/hcGYbBwIEDmTNnDr/88guVK1e+4X1c9bOVk/fqv1z5d5bdbicpKSnD20z7TOXpUGwX9v333xteXl7GlClTjN27dxv9+vUzgoODjdOnTxuGYRg9e/Y0hg0blrb96tWrDXd3d+P999839uzZY4wYMcLw8PAwduzYYdZLyDfZfa9GjRplLFmyxPjrr7+MzZs3Gw8//LDh7e1t7Nq1y6yXkG9iY2ONqKgoIyoqygCMDz/80IiKijKOHDliGIZhDBs2zOjZs2fa9gcPHjR8fX2NF1980dizZ48RGRlpuLm5GYsXLzbrJeSb7L5XH330kTF37lxj//79xo4dO4znnnvOsFqtxvLly816CfnmmWeeMYKCgoyVK1cap06dSrskJCSkbaPfWQ45ea9c9XfWsGHDjN9++804dOiQsX37dmPYsGGGxWIxli5dahiG83ymVITy0Pjx440KFSoYnp6eRpMmTYx169al3da6dWujV69e6bb/4YcfjBo1ahienp5GnTp1jAULFuRzYvNk570aPHhw2ralSpUyOnXqZGzZssWE1Pnv6le8/3u5+v706tXLaN269TX3qV+/vuHp6WlUqVLF+Prrr/M9txmy+17973//M6pWrWp4e3sbRYsWNdq0aWP88ssv5oTPZxm9T0C6z4p+Zznk5L1y1d9Zjz/+uFGxYkXD09PTKFGihHHHHXeklSDDcJ7PlMUwDCNv9zmJiIiIOCeNERIRERGXpSIkIiIiLktFSERERFyWipCIiIi4LBUhERERcVkqQiIiIuKyVIRERETEZakIiYjcgMViYe7cuWbHEJE8oCIkIk6td+/eWCyWay4dOnQwO5qIFALuZgcQEbmRDh068PXXX6db5+XlZVIaESlMtEdIRJyel5cXpUuXTncpUqQI4DhsNWnSJDp27IiPjw9VqlRh1qxZ6e6/Y8cObr/9dnx8fChWrBj9+vUjLi4u3TZfffUVderUwcvLizJlyjBw4MB0t58/f557770XX19fqlevzvz589Nuu3TpEj169KBEiRL4+PhQvXr1a4qbiDgnFSERKfDeeOMN7rvvPrZt20aPHj14+OGH2bNnDwDx8fG0b9+eIkWKsHHjRmbOnMny5cvTFZ1JkyYxYMAA+vXrx44dO5g/fz7VqlVL9xyjRo3iwQcfZPv27XTq1IkePXpw8eLFtOffvXs3ixYtYs+ePUyaNInixYvn3xsgIjmX59O6iojchF69ehlubm6Gn59fusvbb79tGIZjNvCnn3463X2aNm1qPPPMM4ZhGMZnn31mFClSxIiLi0u7fcGCBYbVajVOnz5tGIZhhISEGK+99tp1MwDG66+/nnY9Li7OAIxFixYZhmEYnTt3Nvr06ZM7L1hE8pXGCImI07vtttuYNGlSunVFixZNW27WrFm625o1a8bWrVsB2LNnD+Hh4fj5+aXd3qJFC+x2O/v27cNisXDy5EnuuOOOTDPUq1cvbdnPz4/AwEDOnj0LwDPPPMN9993Hli1buPPOO+natSvNmzfP0WsVkfylIiQiTs/Pz++aQ1W5xcfHJ0vbeXh4pLtusViw2+0AdOzYkSNHjrBw4UKWLVvGHXfcwYABA3j//fdzPa+I5C6NERKRAm/dunXXXK9duzYAtWvXZtu2bcTHx6fdvnr1aqxWKzVr1iQgIIBKlSqxYsWKm8pQokQJevXqxXfffce4ceP47LPPburxRCR/aI+QiDi9pKQkTp8+nW6du7t72oDkmTNn0rhxY2699VamTp3Khg0b+PLLLwHo0aMHI0aMoFevXowcOZJz584xaNAgevbsSalSpQAYOXIkTz/9NCVLlqRjx47ExsayevVqBg0alKV8w4cPp1GjRtSpU4ekpCR+/vnntCImIs5NRUhEnN7ixYspU6ZMunU1a9Zk7969gOMbXd9//z39+/enTJkyTJ8+ndDQUAB8fX1ZsmQJzz33HBEREfj6+nLffffx4Ycfpj1Wr169SExM5KOPPmLo0KEUL16c+++/P8v5PD09eeWVVzh8+DA+Pj60bNmS77//PhdeuYjkNYthGIbZIUREcspisTBnzhy6du1qdhQRKYA0RkhERERcloqQiIiIuCyNERKRAk1H90XkZmiPkIiIiLgsFSERERFxWSpCIiIi4rJUhERERMRlqQiJiIiIy1IREhEREZelIiQiIiIuS0VIREREXJaKkIiIiLis/weVOt3Nnb1SUgAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_34/4025582486.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs = torch.tensor(tokenizer.encode(inputs)).clone().detach().unsqueeze(0)\n","output_type":"stream"},{"name":"stdout","text":"i could pick my lancei ladies hear padible bornaces pad reap moves dew ladies easily darkness te advise apply te behwho behazed te companions fingers pad companions served oppress;\nhe te hear te companions seals claim reap pad companions institute trumpet dry arrived,\nand so my daughter,\nand so my soul,\nand so my soul,\nand so my soul,\nand so my blood,\nand so my blood,\nand i am my daughter,\nand i am my daughter,\nand i am my daughter,\nbut my daughter my daughter's\n","output_type":"stream"}]}]}