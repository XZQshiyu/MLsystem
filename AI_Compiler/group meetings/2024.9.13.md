transformer kv-cache

bottleneck ： HBM -> 寄存器的数据 transfer

两种压缩手段

- 量化
- attention score相近，聚类成一个聚类中心，保留聚类中心

>长序列聚类效果比较好：cluster 内间距短
>
>过去的重要性不一定在未来体现，因此只是考虑 attention score之间的关联性保存有效信息是 有问题的
>
>压缩率：聚类个数
>
>- 压缩率一定时：序列长 > H2O
>
>根据实际的workload判断是否压缩

相同压缩率，同样的内存。

- baseline：选择importance

  聚类方法和 H2O

>H2O, flash-attention
>
>KV-cache

### clustering and quantunming

- 用类中心的attention-score代替

重排：前80%量化，后20%采用聚类中心点代替

sequence length 和 压缩率之间的trade-off

